{"searchDocs":[{"title":"Apache OpenDAL™ participates in Google Summer of Code 2024","type":0,"sectionRef":"#","url":"/blog/apache-opendal-participates-in-gsoc-2024","content":"Hello, everyone! We're writing this blog post to announce that the Apache OpenDAL™ Project will be participating in Google Summer of Code (GSoC) 2024. If you're not eligible or interested in participating in GSoC, then most of this post likely isn't relevant to you; if you are, this should contain some useful information and links. Google Summer of Code (GSoC) is an annual global program organized by Google that aims to bring new contributors to the world of open-source. The program pairs organizations (such as the OpenDAL Project) with contributors (usually students), with the goal of helping the participants make meaningful open-source contributions under the guidance of experienced mentors. Google is sponsoring the 2024 Summer of Code and The Apache Software Foundation (ASF) registered as a mentoring organization. The GSoC applicants now have several weeks to send project proposals to organizations that appeal to them. If their project proposal is accepted, they will embark on a 12-week journey during which they will try to complete their proposed project under the guidance of an assigned mentor. We have prepared a list of project ideas that can serve as inspiration for potential GSoC contributors that would like to send a project proposal to the OpenDAL project. However, applicants can also come up with their own project ideas. You can discuss project ideas or try to find mentors on the maillist or Discord. We have also prepared a proposal guide that should help you with preparing your project proposals. You can start discussing the project ideas with OpenDAL Project maintainers immediately. The project proposal application period starts on March 18, 2024, and ends on April 2, 2024 at 18:00 UTC. Take note of that deadline, as there will be no extensions! If you are interested in contributing to the OpenDAL Project, we encourage you to check out our project idea list and send us a GSoC project proposal! Of course, you are also free to discuss these projects and/or try to move them forward even if you do not intend to (or cannot) participate in GSoC. We welcome all contributors to OpenDAL, as there is always enough work to do. We are excited about this event. Hoping you all feel the same way! This announcement is inspired a lot by the Rust participates in Google Summer of Code 2024.","keywords":"","version":null},{"title":"Apache OpenDAL™ is now Graduated","type":0,"sectionRef":"#","url":"/blog/apache-opendal-graduated","content":"","keywords":"","version":null},{"title":"What's Apache OpenDAL?​","type":1,"pageTitle":"Apache OpenDAL™ is now Graduated","url":"/blog/apache-opendal-graduated#whats-apache-opendal","content":" Apache OpenDAL is a data access layer that allows users to easily and efficiently retrieve data from various storage services in a unified way. Our VISION is access data freely.  OpenDAL could be used as a better SDK for your storage services: A SDK with native integration of retry, logging, metrics, tracing, timeout, throttle, and more.  OpenDAL could be used as a super connector for your storage services: A connector that supports all kinds of storage services from Object Storage (s3, gcs, azblob), File Storage (fs, azdls, hdfs), Consumer Cloud Storage (gdrive, onedrive), Key-Value Storage (rocksdb, sled) to Cache Storage (memcached, moka).  OpenDAL could be used as an elegant client for your storage services: A client with well designed API and many language bindings: Rust, C, Cpp, Dotnet, Go, Haskell, Java, Lua, Node.js, Ocaml, Php, Python, Ruby, Swift and Zig.  Need to access data? Give OpenDAL a try!  async fn main() -&gt; Result&lt;()&gt; { // Init s3 service. let mut builder = services::S3::default(); builder.bucket(&quot;test&quot;); // Init an operator let op = Operator::via_map(builder)? // Add logging .layer(LoggingLayer::default()) .finish(); // Write data op.write(&quot;hello.txt&quot;, &quot;Hello, World!&quot;).await?; // Read data let bs = op.read(&quot;hello.txt&quot;).await?; // Fetch metadata let meta = op.stat(&quot;hello.txt&quot;).await?; let mode = meta.mode(); let length = meta.content_length(); // Delete op.delete(&quot;hello.txt&quot;).await?; Ok(()) }   ","version":null,"tagName":"h2"},{"title":"What's the ASF?​","type":1,"pageTitle":"Apache OpenDAL™ is now Graduated","url":"/blog/apache-opendal-graduated#whats-the-asf","content":" The Apache Software Foundation (ASF) is a nonprofit corporation to support a number of open-source software projects. The Apache Software Foundation exists to provide software for the public good. We believe in the power of community over code, known as The Apache Way. Thousands of people around the world contribute to ASF open source projects every day.  The OpenDAL Community believes the apache way that:  Earned Authority: all individuals are given the opportunity to participate, but their influence is based on publicly earned merit – what they contribute to the community.Community of Peers: individuals participate at the ASF, not organizations.Open Communications: as a virtual organization, the ASF requires all communications related to code and decision-making to be publicly accessible to ensure asynchronous collaboration, as necessitated by a globally-distributed community.Consensus Decision Making: Apache Projects are overseen by a self-selected team of active volunteers who are contributing to their respective projects.Responsible Oversight: The ASF governance model is based on trust and delegated oversight.  The original creators Databend chosen to contribute OpenDAL to the ASF, embracing the Apache way through joining the incubator program.  ","version":null,"tagName":"h2"},{"title":"What's graduation?​","type":1,"pageTitle":"Apache OpenDAL™ is now Graduated","url":"/blog/apache-opendal-graduated#whats-graduation","content":" In the Apache Incubator, the OpenDAL community is learning the Apache Way through daily development activities, growing its community and producing Apache releases.  During the incubation, we:  Consist of 19 committers, including mentors, with 12 serving as PPMC members.Boast 164 contributors.Made 9 releases—averaging at least one per month.Had 7 different release managers to date.Used by 10 known entities and is a dependency for 263 GitHub projects and 18 crates.io packages.Opened 1,200+ issues with 1,100+ successfully resolved.Submitted a total of 2,400+ PRs, most of them have been merged or closed.  The graduation signifies that the OpenDAL Community is recognized as a mature community, which entails:  CODE: OpenDAL is an Apache 2.0 licensed open-source project with accessible, buildable code on GitHub, featuring a traceable history and authenticated code provenance.LICENSE: OpenDAL maintains open-source compliance for all code and dependencies, requires contributor agreements, and clearly documents copyright ownership.Releases: OpenDAL offers standardized, committee-approved source code releases with secure signatures, provides convenience binaries, and has a well-documented, repeatable release process.Quality: OpenDAL is committed to code quality transparency, prioritizes security with quick issue responses, ensures backward compatibility with clear documentation, and actively addresses bug reports in a timely manner.Community: OpenDAL offers a comprehensive homepage, welcomes diverse contributions, promotes a meritocratic approach for active contributors, operates on community consensus, and ensures timely responses to user queries through various channels.Consensus: OpenDAL has a public list of key decision-makers and uses a consensus approach for decisions, documented on its main communication channel. It follows standard voting rules and records all important discussions in writing.Independence: OpenDAL is independent, with contributors from various companies acting on their own, not as representatives of any organization.  ","version":null,"tagName":"h2"},{"title":"What's next?​","type":1,"pageTitle":"Apache OpenDAL™ is now Graduated","url":"/blog/apache-opendal-graduated#whats-next","content":" After graduation, OpenDAL Community will continue to focus on the following aspects under the VISION: access data freely.  ","version":null,"tagName":"h2"},{"title":"More Stable Services​","type":1,"pageTitle":"Apache OpenDAL™ is now Graduated","url":"/blog/apache-opendal-graduated#more-stable-services","content":" OpenDAL now supports 59 services, although only some of them are stable.  stable for OpenDAL means that  Have integration tests covered.Have at least one production user.  The stable service established a feedback loop between the OpenDAL community and its users. Users can submit bug reports or feature requests to the OpenDAL community, which in turn can enhance the service using this feedback while ensuring existing features remain intact.  After graduation, the OpenDAL community will focus on improving the stability of current services instead of just expanding our offerings.  We plan to:  Add features users wanted to services like file version, concurrently list and glob pattern.Add integration tests for newly added services.  ","version":null,"tagName":"h3"},{"title":"More Useful Documents​","type":1,"pageTitle":"Apache OpenDAL™ is now Graduated","url":"/blog/apache-opendal-graduated#more-useful-documents","content":" OpenDAL have good docs for its rust core, but not for other language bindings.  The lack of comprehensive documentation makes OpenDAL challenging for users to operate in Java or Python. Without user feedback, the community is unable to enhance this documentation, leading to a detrimental cycle that must be broken.  After graduation, the OpenDAL community will improve the documentation of other language bindings.  We plan to:  Introduce code generation to automatically create documentation for the service builder due to its numerous configurations.Add more API Docs and examples for other language bindings.  OpenDAL have good docs for its public API, but not for its internal design.  OpenDAL is proud of its elegant design, but it is not well documented. This makes it difficult for new contributors to understand the codebase and make contributions.  After graduation, the OpenDAL community will improve the documentation of its internal design.  We plan to:  Optimize the codebase to make it easier to understand.Add more blog posts to explain the design of OpenDAL.  ","version":null,"tagName":"h3"},{"title":"More Production Users​","type":1,"pageTitle":"Apache OpenDAL™ is now Graduated","url":"/blog/apache-opendal-graduated#more-production-users","content":" OpenDAL requires more production users, as they are vital to the success of our project. Increased user production leads to more valuable feedback, a more engaged contributor base, and a stronger community. We've started the initial loop; let's expand it!  After graduation, the OpenDAL community will focus on attracting more production users.  We plan to:  Optimize the feature set for adoption like uri initiation and config.Expand more ways to use OpenDAL via fuse, cli, S3/WebDAV API, object_store binding.  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Apache OpenDAL™ is now Graduated","url":"/blog/apache-opendal-graduated#conclusion","content":" The OpenDAL Community aims to create a world where users can freely access data across any storage service in any manner they choose. Graduation is just the beginning—let's work together to make our VISION a reality! ","version":null,"tagName":"h2"},{"title":"Apache OpenDAL™ Internal: Data Reading","type":0,"sectionRef":"#","url":"/blog/how-opendal-read-data","content":"","keywords":"","version":null},{"title":"Overall Framework​","type":1,"pageTitle":"Apache OpenDAL™ Internal: Data Reading","url":"/blog/how-opendal-read-data#overall-framework","content":" Before starting to introduce the specific OpenDAL interface, let's first get familiar with the OpenDAL project.  OpenDAL is an Apache Incubator project aimed at helping users access data from various storage services in a unified, convenient, and efficient way. Its project vision is &quot;free access to data&quot;:  Free from services: Any service can be accessed freely through native interfacesFree from implementations: No matter how the underlying implementation is, it can be called in a unified wayFree to integrate: Able to freely integrate with various services and languagesFree to zero cost: Users don't have to pay for features they don't use  On this philosophical foundation, OpenDAL Rust Core can be mainly divided into the following components:  Operator: The outer interface exposed to usersLayers: Specific implementation of different middlewareServices: Specific implementation of different services  From a macroscopic perspective, OpenDAL's data reading call stack would look like this:    All Layers and Services have implemented a unified Accessor interface, erasing all type information when building the Operator. For the Operator, regardless of what services are used or how many middleware are added, all call logic is consistent. This design splits OpenDAL's API into Public API and Raw API, where the Public API is directly exposed to users, providing convenient top-level interfaces, and Raw API is provided to OpenDAL internal developers, maintaining a unified internal interface and providing some convenient implementation.  ","version":null,"tagName":"h2"},{"title":"Operator​","type":1,"pageTitle":"Apache OpenDAL™ Internal: Data Reading","url":"/blog/how-opendal-read-data#operator","content":" OpenDAL's Operator API will adhere to a consistent calling paradigm as much as possible, reducing users' learning and usage costs. For example, OpenDAL offers the following APIs for read:  op.read(path): Reads the entire content of the specified fileop.reader(path): Creates a Reader for streaming readingop.read_with(path).range(1..1024): Reads file content using specified parameters, such as rangeop.reader_with(path).range(1..1024): Creates a Reader for streaming reading with specified parameters  It's not hard to see that read is more like syntactic sugar, allowing users to quickly read files without considering various traits like AsyncRead. The reader provides more flexibility, implementing widely-used community traits like AsyncSeek, AsyncRead, allowing more flexible data reading. read_with and reader_with assist users in specifying various parameters in a more natural way through Future Builder functions.  The internal logic of the Operator would look like this:    Its main job is to encapsulate the interface for the user:  Completing the construction of OpRead: the args for read operation.Calling the read function provided by AccessorWrapping the returned value as Reader and implementing interfaces like AsyncSeek, AsyncRead, etc., based on Reader  ","version":null,"tagName":"h2"},{"title":"Layers​","type":1,"pageTitle":"Apache OpenDAL™ Internal: Data Reading","url":"/blog/how-opendal-read-data#layers","content":" A little secret here is that OpenDAL will automatically apply some Layers to the Service to implement some internal logic. As of the completion of this article, OpenDAL's automatically added Layers include:  ErrorContextLayer: Injects context information, such as scheme, path, etc., into all returned errors of OperationCompleteLayer: Adds necessary capabilities to services, such as adding seek support to s3TypeEraseLayer: Implements type erasure, uniformly erasing associated types in Accessor, so users don't need to carry generic parameters when using it  Here, ErrorContextLayer and TypeEraseLayer are relatively simple and won't be elaborated on. The focus is on CompleteLayer, aimed at adding seek or next support to OpenDAL's returned Reader in a zero-cost way, so users don't have to re-implement it. OpenDAL initially returned Reader and SeekableReader through different function calls in early versions, but the actual user feedback was not very good; almost all users were using SeekableReader. Therefore, OpenDAL subsequently added seek support as the first priority to the internal Read trait during the refactor:  pub trait Read: Unpin + Send + Sync { /// Read bytes asynchronously. fn poll_read(&amp;mut self, cx: &amp;mut Context&lt;'_&gt;, buf: &amp;mut [u8]) -&gt; Poll&lt;Result&lt;usize&gt;&gt;; /// Seek asynchronously. /// /// Returns `Unsupported` error if underlying reader doesn't support seek. fn poll_seek(&amp;mut self, cx: &amp;mut Context&lt;'_&gt;, pos: io::SeekFrom) -&gt; Poll&lt;Result&lt;u64&gt;&gt;; /// Stream [`Bytes`] from underlying reader. /// /// Returns `Unsupported` error if underlying reader doesn't support stream. /// /// This API exists for avoiding bytes copying inside async runtime. /// Users can poll bytes from underlying reader and decide when to /// read/consume them. fn poll_next(&amp;mut self, cx: &amp;mut Context&lt;'_&gt;) -&gt; Poll&lt;Option&lt;Result&lt;Bytes&gt;&gt;&gt;; }   To implement a service's reading capability in OpenDAL, one needs to implement this trait, which is an internal interface and will not be directly exposed to users. Among them:  poll_read is the most basic requirement; all services must implement this interface.When the service natively supports seek, poll_seek can be implemented, and OpenDAL will correctly dispatch, such as local fs;When the service natively supports next, meaning it returns streaming Bytes, poll_next can be implemented, like HTTP-based services, where the underlying layer is a TCP Stream, and hyper will encapsulate it as a bytes stream.  Through the Read trait, OpenDAL ensures that all services can expose their native support capabilities as much as possible, thereby achieving efficient reading for different services.  Based on this trait, OpenDAL will complete according to the capabilities supported by each service:  Both seek/next are supported: Direct returnNo support for next: Encapsulate using StreamableReader to simulate next supportNo support for seek: Encapsulate using ByRangeSeekableReader to simulate seek supportNeither seek/next supported: Encapsulate using both methods  ByRangeSeekableReader mainly utilizes the service's ability to support range read, dropping the current reader when the user seeks and initiating a new request at the specified location.  OpenDAL exposes a unified Reader implementation through CompleteLayer, so users don't have to worry about whether the underlying service supports seek; OpenDAL will always choose the optimal way to initiate the request.  ","version":null,"tagName":"h2"},{"title":"Services​","type":1,"pageTitle":"Apache OpenDAL™ Internal: Data Reading","url":"/blog/how-opendal-read-data#services","content":" After the completion of the Layers, it's time to call the specific implementation of the Service. Here, the most common services fs and s3 are used as examples to explain how data is read.  ","version":null,"tagName":"h2"},{"title":"Service fs​","type":1,"pageTitle":"Apache OpenDAL™ Internal: Data Reading","url":"/blog/how-opendal-read-data#service-fs","content":" tokio::fs::File implements tokio::AsyncRead and tokio::AsyncSeek. Using async_compat::Compat, we have transformed it into futures::AsyncRead and futures::AsyncSeek. Based on this, we provide a built-in function oio::into_read_from_file to transform it into a type that implements oio::Read.  There's nothing particularly complex in the implementation of oio::into_read_from_file; read and seek are mostly calling the functions provided by the incoming File type. The tricky part is about the correct handling of seek and range: seeking to the right side of the range is allowed, and this will not cause an error, and reading will only return empty, but seeking to the left side of the range is illegal, and the Reader must return InvalidInput for proper upper-level handling.  Interesting history: there was an issue in the initial implementation of this part, discovered during fuzz testing.  ","version":null,"tagName":"h3"},{"title":"Services s3​","type":1,"pageTitle":"Apache OpenDAL™ Internal: Data Reading","url":"/blog/how-opendal-read-data#services-s3","content":" S3 is an HTTP-based service, and opendal provides a lot of HTTP-based wrappers to help developers reuse logic; they only need to build a request and return a well-constructed Body. OpenDAL Raw API encapsulates a set of reqwest-based interfaces, and the HTTP GET interface returns a Response&lt;IncomingAsyncBody&gt;:  /// IncomingAsyncBody carries the content returned by remote servers. pub struct IncomingAsyncBody { /// # TODO /// /// hyper returns `impl Stream&lt;Item = crate::Result&lt;Bytes&gt;&gt;` but we can't /// write the types in stable. So we will box here. /// /// After [TAIT](https://rust-lang.github.io/rfcs/2515-type_alias_impl_trait.html) /// has been stable, we can change `IncomingAsyncBody` into `IncomingAsyncBody&lt;S&gt;`. inner: oio::Streamer, size: Option&lt;u64&gt;, consumed: u64, chunk: Option&lt;Bytes&gt;, }   The stream contained in this body is the bytes stream returned by reqwest, and opendal implements content length checks and read support on this basis.  Here's an extra note about a small pitfall with reqwest/hyper: reqwest and hyper do not check the returned content length, so an illegal server may return a data volume that does not match the expected content length instead of an error, leading to unexpected data behavior. OpenDAL specifically added checks here, returning ContentIncomplete when data is insufficient and ContentTruncated when data exceeds expectations, avoiding users receiving illegal data.  ","version":null,"tagName":"h3"},{"title":"Conclusion​","type":1,"pageTitle":"Apache OpenDAL™ Internal: Data Reading","url":"/blog/how-opendal-read-data#conclusion","content":" This article introduces from top to bottom how OpenDAL implements data reading:  Operator is responsible for exposing user-friendly interfacesLayers are responsible for completing the capabilities of the servicesServices are responsible for the specific implementation of different services  Throughout the entire chain, OpenDAL adheres as much as possible to the principle of zero cost, prioritizing the use of native service capabilities, then considering simulation through other methods, and finally returning unsupported errors. Through this three-tier design, users don't need to understand the details of the underlying service, nor do they need to integrate different service SDKs to easily call op.read(path) to access data in any storage service.  This is: How OpenDAL read data freely! ","version":null,"tagName":"h2"},{"title":"Apache OpenDAL™: Access Data Freely","type":0,"sectionRef":"#","url":"/blog/opendal-access-data-freely","content":"","keywords":"","version":null},{"title":"What is OpenDAL?​","type":1,"pageTitle":"Apache OpenDAL™: Access Data Freely","url":"/blog/opendal-access-data-freely#what-is-opendal","content":" OpenDAL is a data access layer that allows users to easily and efficiently retrieve data from various storage services in a unified way.  Data Access Layer means: OpenDAL is in a critical position in the data read-write process. We shield the implementation details of different storage backends and provide a set of unified interface abstractions externally.  Next, let's try to answer &quot;What OpenDAL is not&quot; and deconstruct OpenDAL from another perspective:  ","version":null,"tagName":"h2"},{"title":"Opendal Is Not a Proxy Service​","type":1,"pageTitle":"Apache OpenDAL™: Access Data Freely","url":"/blog/opendal-access-data-freely#opendal-is-not-a-proxy-service","content":" OpenDAL is provided in the form of a library, not as a service or application that proxies various storage backends.  If you want to integrate OpenDAL into an existing project, you need to call OpenDAL's interface directly through the bindings supported by OpenDAL to access the storage services.  ","version":null,"tagName":"h3"},{"title":"Opendal Is Not an SDK Aggregator​","type":1,"pageTitle":"Apache OpenDAL™: Access Data Freely","url":"/blog/opendal-access-data-freely#opendal-is-not-an-sdk-aggregator","content":" Although OpenDAL replaces various SDKs in the application architecture, it is not implemented as an SDK aggregator.  In other words, OpenDAL does not simply call various storage service SDKs. We have developed our own docking with various storage services based on a unified Rust core to ensure that the differences between services are smoothed out.  For example, for S3, OpenDAL manually constructs HTTP requests and parses HTTP responses to ensure that all behaviors comply with API specifications and are fully under the control of OpenDAL. Due to OpenDAL's native takeover of the data access process, we can easily implement unified retry and logging mechanisms for various storage backends and ensure behavioral consistency.  For compatible services with S3, due to the limitations of native storage services and differences in API implementation, compatibility and behavioral details may differ from S3. For example, OSS needs to set an independent header to ensure consistent behavior for Range. In addition to docking with native storage services, OpenDAL will also perform targeted processing for compatible services to ensure users' data access experience.  ","version":null,"tagName":"h3"},{"title":"Advantages of OpenDAL​","type":1,"pageTitle":"Apache OpenDAL™: Access Data Freely","url":"/blog/opendal-access-data-freely#advantages-of-opendal","content":" OpenDAL is not the only project dedicated to providing data access abstraction, but compared to other similar projects, OpenDAL has the following advantages:  ","version":null,"tagName":"h2"},{"title":"Rich Service Support​","type":1,"pageTitle":"Apache OpenDAL™: Access Data Freely","url":"/blog/opendal-access-data-freely#rich-service-support","content":" OpenDAL supports dozens of storage services, covering a wide range of scenarios and supporting on-demand selection:  Standard Storage Protocols: FTP, HTTP, SFTP, WebDAV, etc.Object Storage Services: azblob, gcs, obs, oss, s3, etc.File Storage Services: fs, azdls, hdfs, webhdfs, ipfs, etc.Consumer Cloud Storage Service: Google Drive, OneDrive, Dropbox, etc.Key-Value Storage Service: Memory, Redis, Rocksdb, etc.Cache Storage Service: Ghac, Memcached, etc.  ","version":null,"tagName":"h3"},{"title":"Complete Cross-Language Bindings​","type":1,"pageTitle":"Apache OpenDAL™: Access Data Freely","url":"/blog/opendal-access-data-freely#complete-cross-language-bindings","content":" With Rust as the core, OpenDAL now provides binding support for multiple languages such as Python/Node.js/Java/C and is also actively developing bindings for other languages.  Cross-language bindings not only provide unified storage access abstractions for other languages but also follow naming conventions and development habits that are common in various languages as much as possible to pave the way for quick use.  ","version":null,"tagName":"h3"},{"title":"Powerful Middleware Support​","type":1,"pageTitle":"Apache OpenDAL™: Access Data Freely","url":"/blog/opendal-access-data-freely#powerful-middleware-support","content":" OpenDAL offers native layer support, enabling users to implement middleware or intercept for all operations.  Error Retry: OpenDAL supports fine-grained error retry capabilities. In addition to common request retries, it supports breakpoint resumable transmission without having to re-read the entire file.Observability: OpenDAL implements logging,tracing,and metrics support for all operations. Turning on middleware can directly obtain observability capabilities for storage.Concurrency control, flow control, fuzz testing, and more.  ","version":null,"tagName":"h3"},{"title":"Easy to Use​","type":1,"pageTitle":"Apache OpenDAL™: Access Data Freely","url":"/blog/opendal-access-data-freely#easy-to-use","content":" OpenDAL's API has been well designed and polished in actual use. The documentation covers everything and is easy to get started with. Here's an example of using Python bindings to access HDFS:  import opendal op = opendal.Operator(&quot;hdfs&quot;, name_node=&quot;hdfs://192.16.8.10.103&quot;) op.read(&quot;path/to/file&quot;)   ","version":null,"tagName":"h3"},{"title":"Use Cases of OpenDAL​","type":1,"pageTitle":"Apache OpenDAL™: Access Data Freely","url":"/blog/opendal-access-data-freely#use-cases-of-opendal","content":" Currently, OpenDAL is widely used in various scenarios that require cloud-native capabilities, including but not limited to databases, data pipelines, and caches. The main user cases include:  Databend: A modern Elasticity and Performance cloud data warehouse. Using OpenDAL to read and write persistent data (s3, azblob, gcs, hdfs, etc.) and cache data (fs, redis, rocksdb, moka, etc.).GreptimeDB: An open-source, cloud-native, distributed time-series database. Using OpenDAL to read and write persistent data (s3, azblob, etc.).mozilla/sccache: sccache is ccache with cloud storage. Using OpenDAL to read and write cache data (s3 and ghac, etc.).RisingWave: A Distributed SQL Database for Stream Processing. Using OpenDAL to read and write persistent data (s3, azblob, hdfs, etc.).Vector: A high-performance observability data pipeline. Using OpenDAL to write persistent data (currently mainly using hdfs).  ","version":null,"tagName":"h3"},{"title":"Future Plans of OpenDAL​","type":1,"pageTitle":"Apache OpenDAL™: Access Data Freely","url":"/blog/opendal-access-data-freely#future-plans-of-opendal","content":" In addition to further meeting the needs of cloud-native data access, OpenDAL will continue to expand user scenarios and actively explore its use in data science and mobile applications. At the same time, OpenDAL will continue to polish its existing implementations and bindings to provide users with a better integration experience.  OpenDAL will also explore how to improve users' workflows in data management and service integration:  Polish the oli command-line tool to help users manage data painlessly.Implement the oay proxy service to provide users with high-quality compatible APIs.  In addition, since OpenDAL is currently a cross-language project, we also plan to write a series of introductory tutorials to help everyone learn OpenDAL from scratch while learning the language. ","version":null,"tagName":"h2"},{"title":"Way to Go: OpenDAL successfully entered Apache Incubator","type":0,"sectionRef":"#","url":"/blog/opendal-entered-apache-incubator","content":"","keywords":"","version":null},{"title":"What is OpenDAL?​","type":1,"pageTitle":"Way to Go: OpenDAL successfully entered Apache Incubator","url":"/blog/opendal-entered-apache-incubator#what-is-opendal","content":" Data is one of the most important assets in the future, and data access is the key for realizing data value.  There are various kinds of storage services in the market, each with its own unique interfaces and features, which bring a lot of complexity and inconvenience to data access.  OpenDAL provides a unified, simple, efficient, reliable, and observable data access layer that allows developers to seamlessly use different storage services and enjoy the best user experience.    OpenDAL simplifies the process of interfacing different storage services, and provides features such as automatic retry, request optimization, and observability. With OpenDAL, developers can directly access a bunch of storage services, without having to understand and master the details of specific SDKs.  OpenDAL's features include but are not limited to:  Support for dozens of storage services, including local file system, HDFS, S3, OSS, etc.Provide a unified data access interface, without worrying about the underlying storage details.Support for various common data operations, including read, write, list, etc.Support for automatic retry, request optimization, and observability mechanisms.Zero cost, directly mapped to API calls.Cross-language bindings: Python, Node.js, C (being worked on), etc.  ","version":null,"tagName":"h2"},{"title":"The Story about OpenDAL​","type":1,"pageTitle":"Way to Go: OpenDAL successfully entered Apache Incubator","url":"/blog/opendal-entered-apache-incubator#the-story-about-opendal","content":" ","version":null,"tagName":"h2"},{"title":"Born for Universal Data Access​","type":1,"pageTitle":"Way to Go: OpenDAL successfully entered Apache Incubator","url":"/blog/opendal-entered-apache-incubator#born-for-universal-data-access","content":" OpenDAL originated from the vision of creating a universal, unified and user-friendly data access layer. It came into being in late 2021, initially as a component of the Databend project.  On December 21, 2021, Xuanwo embarked on the design and re-implementation of Databend's storage access layer, dal2: Add basic operations of read, write, stat, delete.On December 27, 2021, the proposal: Vision of Databend DAL was put forward and discussed. On December 29th, dal2's implementation was integrated into Databend.On February 14th 2022 , dal2 officially separated from Databend's code repository and became a standalone top-level project. It was formally renamed OpenDAL.  ","version":null,"tagName":"h3"},{"title":"From One to Multiple​","type":1,"pageTitle":"Way to Go: OpenDAL successfully entered Apache Incubator","url":"/blog/opendal-entered-apache-incubator#from-one-to-multiple","content":" Thanks to Xuanwo, ClSlaid and many other contributors, OpenDAL quickly became a data access layer that supports mainstream storage services such as AWS S3 / Azure Blob / GCS / HDFS, and provided cross-cloud native storage and access support for Databend's COPY INTO, Stage, Storage.  GreptimeDB was the first large-scale Rust database project to actively use OpenDAL after Databend. Later, with Xuanwo's efforts, sccache under Mozilla also tried to use OpenDAL to take over the storage layer. In order to provide more comprehensive support, OpenDAL soon added support for GitHub Action Cache.  Then, RisingWave and Vector were supported as well. The number of OpenDAL users started to grow. More and more users choose OpenDAL as their storage access layer.  ","version":null,"tagName":"h3"},{"title":"Sky's the Limit​","type":1,"pageTitle":"Way to Go: OpenDAL successfully entered Apache Incubator","url":"/blog/opendal-entered-apache-incubator#skys-the-limit","content":" OpenDAL has established a small community and formed a product matrix. In addition to the Rust - opendal, it also provides Python - opendal and Nodejs - opendal bindings.  OpenDAL has released 99 versions since its open source, with 700+ GitHub stars, 349K downloads, and 48 developers. The project has been actively updated. We sincerely thank every contributor for their efforts and dedication.  Being a part of Apache incubator is an important milestone in OpenDAL's development history. We hope to leverage ASF's platform and resources to let OpenDAL focus on providing a neutral, vendor-free, painless, and efficient storage access layer, and better serve the developers.  We expect OpenDAL to be widely used in the following application scenarios:  Data analysis: OpenDAL can help data analysts quickly read or write data from different storage services, and perform various format conversions and operations.Data science: OpenDAL can help data scientists easily get or save data from different storage services, and perform various preprocessing and postprocessing.Data engineering: OpenDAL can help data engineers efficiently build and manage data pipelines between different storage services, and perform various monitoring and tuning.  ","version":null,"tagName":"h3"},{"title":"Acknowledgements​","type":1,"pageTitle":"Way to Go: OpenDAL successfully entered Apache Incubator","url":"/blog/opendal-entered-apache-incubator#acknowledgements","content":" From Xuanwo  Hello everyone, I'm Xuanwo, the Committer of Apache OpenDAL.  The OpenDAL project embodies my personal dream. Now it has entered the Apache incubator with the collaboration of the community. I feel very happy at this moment. Thank you all contributors for your contributions, thank Databend Labs for your support, thank Champion tison for your guidance, thank Mentors ningjiang, wusheng, tedliu and hexiaoqiao for your advice.  Let us follow the guidance of Apache Way to build a community together and create value for users by providing free, painless and efficient data access experience!  ","version":null,"tagName":"h2"},{"title":"Join Apache OpenDAL Community​","type":1,"pageTitle":"Way to Go: OpenDAL successfully entered Apache Incubator","url":"/blog/opendal-entered-apache-incubator#join-apache-opendal-community","content":" We welcome developers and users who are interested in participating in OpenDAL project to join OpenDAL community and follow OpenDAL's latest news. You can get more information through the following ways:  Visit OpenDAL official website: https://opendal.apache.orgExplore OpenDAL GitHub repository: https://github.com/apache/opendalJoin OpenDAL Discord channel: https://opendal.apache.org/discordSubscribe to OpenDAL mailing list: dev@opendal.apache.org ","version":null,"tagName":"h2"},{"title":"OwO #1: The v0.40 Release","type":0,"sectionRef":"#","url":"/blog/owo-1","content":"","keywords":"","version":null},{"title":"Outcome​","type":1,"pageTitle":"OwO #1: The v0.40 Release","url":"/blog/owo-1#outcome","content":" OpenDAL now comprises four primary components:  Core: The core library written in Rust.Bindings: Language bindings powered by the OpenDAL Rust core.Applications: Applications built using the OpenDAL Rust core.Integrations: Collaborations with other projects.  ","version":null,"tagName":"h2"},{"title":"Core​","type":1,"pageTitle":"OwO #1: The v0.40 Release","url":"/blog/owo-1#core","content":" Unifying Append and Write Functions​  OpenDAL has supported append operations since v0.36. We've found, however, that this led to significant duplication between append and write. As a result, we've streamlined the two functionalities into a single write function. Our users can now:  let mut w = op.writer_with(&quot;test.txt&quot;).append(true).await?; w.write(content_a).await?; w.write(content_b).await?; w.close().await?;   This way, users can reuse the Writer in their own logic without handling append separately.  New Lister API​  To improve API consistency, we've made some adjustments to our listing functions. We've added list and list_with methods that perform single operations and renamed the original list to lister and lister_with.  // Old API let lister: Lister = op.list(&quot;dir&quot;).await?; // New API let entries: Vec&lt;Entry&gt; = op.list(&quot;dir&quot;).await?; let lister: Lister = op.lister(&quot;dir&quot;).await?;   This brings uniformity to our API offerings.  List With Metakey​  To speed up list operations, OpenDAL can now fetch and store metadata during the listing process. This eliminates the need for separate metadata calls:  let entries: Vec&lt;Entry&gt; = op .list_with(&quot;dir/&quot;) .metakey(Metakey::ContentLength | Metakey::ContentType).await?; // Use the metadata directly! let meta: &amp;Metadata = entries[0].metadata();   This makes metadata retrieval more intuitive.  Buffered Writer​  We've added general buffer support to optimize writing operations.  let w = op.writer_with(&quot;path/to/file&quot;).buffer(8 * 1024 * 1024).await?   Others​  Other improvements in the core library can be found in our CHANGELOG.  ","version":null,"tagName":"h3"},{"title":"Bindings​","type":1,"pageTitle":"OwO #1: The v0.40 Release","url":"/blog/owo-1#bindings","content":" C++​  opendal-cpp is ready for its first release! Welcome to check it out and give us some feedback.  Haskell​  opendal-hs is ready for its first release! Welcome to check it out and give us some feedback.  Java​  opendal-java enabled more available services in this release, allowing user to visit services like redis that not enabled by default in rust core. And opendal-java enabled blocking layer to allow users visit services like s3 in blocking way.  Welcome to integrate opendal-java into your project and give us some feedback.  New bindings!​  opendal-dotnetopendal-php  ","version":null,"tagName":"h3"},{"title":"Applications​","type":1,"pageTitle":"OwO #1: The v0.40 Release","url":"/blog/owo-1#applications","content":" oay​  oay is OpenDAL Gateway that allows users to access OpenDAL services via existing protocols like s3 and webdav. It works like a proxy that forwarding requests to OpenDAL services.  In this release, we implement basic webdav support. Users can convert any storage services to a webdav server!  oli​  oli is OpenDAL CLI that allows users to access storage services via CLI like s3cmd and gcloud does.  We fixed some experience issues in this release and improved some docs. Welcome to try it out and give us some feedback.  ","version":null,"tagName":"h3"},{"title":"Integrations​","type":1,"pageTitle":"OwO #1: The v0.40 Release","url":"/blog/owo-1#integrations","content":" object_store​  object_store instead to implement object_store's trait over OpenDAL Operator so that users can use OpenDAL as a backend for object_store.  object_store is mostly functional, but there are some edge use cases that OpenDAL has yet to support.  So far, this release hasn't seen progress in this area; we are awaiting the resolution of the issue Allow list paths that do not end with /.  ","version":null,"tagName":"h3"},{"title":"Working​","type":1,"pageTitle":"OwO #1: The v0.40 Release","url":"/blog/owo-1#working","content":" We are working on the following things:  object_store support: Make object_store integration works and find a user for it.Remove the / limitation for path, so we can list a path without ending with /.Expand the start-after support to more services (Address #2786).  ","version":null,"tagName":"h2"},{"title":"Outlook​","type":1,"pageTitle":"OwO #1: The v0.40 Release","url":"/blog/owo-1#outlook","content":" We are exploring some innovative ideas:  OpenDAL REST/gRPC API: A REST/gRPC Server for OpenDAL.OpenDAL Cache: OpenDAL native cache libs that allowing users to access data more efficiently.OpenDAL File System: A read-only file system that built upon OpenDAL in rust!kio-opendal: A kio plugin powered by OpenDAL that allows users to visit different storage services in KDE Dolphin.gvfs-opendal: A gvfs plugin powered by OpenDAL that allows users to visit different storage services in GNOME Files  Feel free to join in the discussion!  ","version":null,"tagName":"h2"},{"title":"Summary​","type":1,"pageTitle":"OwO #1: The v0.40 Release","url":"/blog/owo-1#summary","content":" This marks our first OpenDAL OwO post. We welcome your feedback. ","version":null,"tagName":"h2"},{"title":"Community","type":0,"sectionRef":"#","url":"/community/","content":"","keywords":"","version":"Next"},{"title":"Mailing list​","type":1,"pageTitle":"Community","url":"/community/#mailing-list","content":" Name\tDesc\tSubscribe\tUnsubscribe\tPost\tArchivedev@opendal.apache.org\tDevelopment related discussions\tSubscribe\tUnsubscribe\tPost\tArchive commits@opendal.apache.org\tAll commits to our repositories\tSubscribe\tUnsubscribe\tRead only list\tArchive  Please make sure you are subscribed to the mailing list you are posting to!  If you are not subscribed to the mailing list, your message will either be rejected or you won't receive the response.  ","version":"Next","tagName":"h2"},{"title":"How to subscribe to a mailing list​","type":1,"pageTitle":"Community","url":"/community/#how-to-subscribe-to-a-mailing-list","content":" Before you can post a message to a mailing list, you need to subscribe to the list first.  Send an email without any contents or subject to listname-subscribe@opendal.apache.org. (replace listname with dev or user)Wait till you receive an email with the subject &quot;confirm subscribe to listname@opendal.apache.org&quot;. Reply to that email, without editing the subject or including any contents.Wait till you receive an email with the subject &quot;WELCOME to listname@opendal.apache.org&quot;.  If you email us with a code snippet, make sure that:  you do not link to files in external services as such files can change, get deleted or the link might break and thus make an archived email thread uselessyou paste text instead of screenshots of textyou keep formatting when pasting code to keep the code readablethere are enough import statements to avoid ambiguities  ","version":"Next","tagName":"h3"},{"title":"Issue tracker​","type":1,"pageTitle":"Community","url":"/community/#issue-tracker","content":" We use GitHub Issues to track all code related issues: https://github.com/apache/opendal/issues  You must have a GitHub account to log cases and issues.  ","version":"Next","tagName":"h2"},{"title":"Bug reports​","type":1,"pageTitle":"Community","url":"/community/#bug-reports","content":" Found bug? Enter an issue in the issue tracker.  Before submitting an issue, please:  Verify that the bug does in fact exist.Search the issue tracker to verify there is no existing issue reporting the bug you've found.Consider tracking down the bug yourself in the source code of OpenDAL and submitting a patch along with your bug report. This is a great time saver for the OpenDAL developers and helps ensure the bug will be fixed quickly.  ","version":"Next","tagName":"h3"},{"title":"Enhancement​","type":1,"pageTitle":"Community","url":"/community/#enhancement","content":" Enhancements or new feature proposals are also welcome. The more concrete and rationale the proposal is, the greater the chance it will be incorporated into future releases.  ","version":"Next","tagName":"h3"},{"title":"Source code​","type":1,"pageTitle":"Community","url":"/community/#source-code","content":" OpenDAL core repository: https://github.com/apache/opendal  ","version":"Next","tagName":"h2"},{"title":"Upcoming Community Events​","type":1,"pageTitle":"Community","url":"/community/#upcoming-community-events","content":" For now, we have a single community event known as the Community Sync Meeting. This meeting is open to everyone.  During the meeting, we will cover various topics including project status, roadmap updates, and other relevant discussions. We will also have a Q&amp;A session at the end of the meeting.  Attending the meeting presents a valuable opportunity for you to meet fellow community members and gain deeper insights into the project. Moreover, it provides an excellent chance for active involvement in the project's activities.  We currently organize the community sync meeting every three weeks, with one scheduled at 09:00 UTC+8 and the other at 19:00 UTC+8. These two meeting times alternate between each three-week cycle.  The following is the calendar of the community events:    If you prefer to add these events to your personal calendar, please use this iCal link:Add to your calendar.  ","version":"Next","tagName":"h2"},{"title":"People​","type":1,"pageTitle":"Community","url":"/community/#people","content":" Thank you to all the contributors for your selfless dedication and expertise in making this project more comprehensive and valuable. We sincerely appreciate your support and efforts!  ","version":"Next","tagName":"h2"},{"title":"PMC members and Committers​","type":1,"pageTitle":"Community","url":"/community/#pmc-members-and-committers","content":" The committers list could be found here.  ","version":"Next","tagName":"h3"},{"title":"Contributors​","type":1,"pageTitle":"Community","url":"/community/#contributors","content":" The contributor list could be found here. ","version":"Next","tagName":"h3"},{"title":"Generate release note","type":0,"sectionRef":"#","url":"/community/committers/reference/generate_release_note","content":"Generate release note This document describes how to generate release notes using GitHub: Go to https://github.com/apache/opendal/releases/new to start a new release.Fill the tag with draft.Click on Generate release notes to generate them.Copy the generated content and close the page. Please note that we only use this feature to generate release notes, so please do not click on Publish Release or Save draft. We will publish it after creating the tag.","keywords":"","version":"Next"},{"title":"Onboarding","type":0,"sectionRef":"#","url":"/community/committers/onboarding","content":"","keywords":"","version":"Next"},{"title":"Submit CLA​","type":1,"pageTitle":"Onboarding","url":"/community/committers/onboarding#submit-cla","content":" Download the ICLA from https://www.apache.org/licenses/contributor-agreements.html#clas. If a corporation assigns employees to work on an Apache project, please download the CCLA.Complete the ICLA based on your particulars. Please note: The address field should be filled out accurately and in detail.You need to choose a unique ApacheID that hasn't been taken. Check https://people.apache.org/committer-index.html to see which IDs are still available. Sign the document by hand or by electronic signature Manually sign a printed copy, then scan it to produce a pdf.Digitally draw a signature on the document: Detail Instruction.Sign the document using PGP: Detail Instruction. Send your icla.pdf (and icla.pdf.asc if PGP-signed) to secretary@apache.org.  After waiting for some time, you will receive an email notifying you that your CLA has been successfully recorded.  ","version":"Next","tagName":"h2"},{"title":"Setup ASF Account​","type":1,"pageTitle":"Onboarding","url":"/community/committers/onboarding#setup-asf-account","content":" When receiving an email with the subject &quot;Welcome to the Apache Software Foundation&quot; from root@apache.org, we can begin setting up an ASF account.  ","version":"Next","tagName":"h2"},{"title":"Setup LDAP Password​","type":1,"pageTitle":"Onboarding","url":"/community/committers/onboarding#setup-ldap-password","content":" Go to https://id.apache.org/reset/enter and enter your ApacheID.Check your email and click the provided link to reset your password.  ","version":"Next","tagName":"h3"},{"title":"Link ASF Account to GitHub​","type":1,"pageTitle":"Onboarding","url":"/community/committers/onboarding#link-asf-account-to-github","content":" Navigate to https://gitbox.apache.org/boxer/ and enter your ApacheID and password.Click &quot;Authenticate with GitHub&quot; and follow the given instructions to link your ASF account to GitHub.Check your email titled &quot;[GitHub] @asfgit has invited you to join the @apache organization&quot; and accept the invitation.Wait momentarily, and the website will refresh on its own.(If you do not enable 2FA on GitHub) Please follow the instruction.  Your ApacheID and GitHub ID will now both appear on https://gitbox.apache.org/boxer/. Congrats on successfully linking your ASF account to GitHub!  ","version":"Next","tagName":"h3"},{"title":"Email Settings​","type":1,"pageTitle":"Onboarding","url":"/community/committers/onboarding#email-settings","content":" Note: Apache does not provide a mailbox directly.  ","version":"Next","tagName":"h2"},{"title":"Receive Email​","type":1,"pageTitle":"Onboarding","url":"/community/committers/onboarding#receive-email","content":" You can change your forwarding email address at Apache Account Utility Platform  ","version":"Next","tagName":"h3"},{"title":"Send Email​","type":1,"pageTitle":"Onboarding","url":"/community/committers/onboarding#send-email","content":" To send emails using your apache.org address, configure your email client to leverage the mail-relay service. For specifics, refer to this guide.  Here's an illustration for Gmail users:  Open Gmail settings and select &quot;See all settings&quot;.Navigate to &quot;Accounts and Import&quot;, then locate &quot;Send mail as&quot;.Click &quot;Add another email address&quot; and enter your name and apache.org email address.Input the SMTP server information: SMTP Server: mail-relay.apache.orgPort: 587Username: your apacheIDPassword: your apacheID passwordSecured connection using TLS Click &quot;Add account&quot; and you will receive an email from Gmail that need to confirm.    ","version":"Next","tagName":"h3"},{"title":"Subscribe to Mailing List​","type":1,"pageTitle":"Onboarding","url":"/community/committers/onboarding#subscribe-to-mailing-list","content":" Send email to dev-subscribe@opendal.apache.orgYou will receive an email with the subject &quot;confirm subscribe to dev@opendal.apache.org&quot;Reply to the email with &quot;Confirm&quot; in the body  If you receive an email with the subject &quot;WELCOME to dev@opendal.apache.org&quot;, you have successfully subscribed to the mailing list.  ","version":"Next","tagName":"h3"},{"title":"Setup 1password​","type":1,"pageTitle":"Onboarding","url":"/community/committers/onboarding#setup-1password","content":" OpenDAL offers a 1Password open-source team license for conducting local integration tests (Thanks to 1Password!). Once you have been added to OpenDAL's committer list, one of the PMC members will invite you to join the team.  Please download your preferred clients to begin using it. You can create your own vault that is accessible only by yourself. Neither the 1password team nor OpenDAL PMC members can access it unless you choose to share it.  ","version":"Next","tagName":"h2"},{"title":"Summit PR for News​","type":1,"pageTitle":"Onboarding","url":"/community/committers/onboarding#summit-pr-for-news","content":" Add your name and GitHub ID to the website/community/news.md file and submit a PR for the website. ","version":"Next","tagName":"h2"},{"title":"Setup GPG key","type":0,"sectionRef":"#","url":"/community/committers/reference/setup_gpg","content":"","keywords":"","version":"Next"},{"title":"Install GPG​","type":1,"pageTitle":"Setup GPG key","url":"/community/committers/reference/setup_gpg#install-gpg","content":" For more details, please refer to GPG official website. Here shows one approach to install GPG with apt:  sudo apt install gnupg2   ","version":"Next","tagName":"h2"},{"title":"Generate GPG Key​","type":1,"pageTitle":"Setup GPG key","url":"/community/committers/reference/setup_gpg#generate-gpg-key","content":" Attentions:  Name is best to keep consistent with your full name of Apache ID;Email should be the Apache email;Name is best to only use English to avoid garbled.  Run gpg --full-gen-key and complete the generation interactively:  gpg (GnuPG) 2.2.20; Copyright (C) 2020 Free Software Foundation, Inc. This is free software: you are free to change and redistribute it. There is NO WARRANTY, to the extent permitted by law. Please select what kind of key you want: (1) RSA and RSA (default) (2) DSA and Elgamal (3) DSA (sign only) (4) RSA (sign only) (14) Existing key from card Your selection? 1 # input 1 RSA keys may be between 1024 and 4096 bits long. What keysize do you want? (2048) 4096 # input 4096 Requested keysize is 4096 bits Please specify how long the key should be valid. 0 = key does not expire &lt;n&gt; = key expires in n days &lt;n&gt;w = key expires in n weeks &lt;n&gt;m = key expires in n months &lt;n&gt;y = key expires in n years Key is valid for? (0) 0 # input 0 Key does not expire at all Is this correct? (y/N) y # input y GnuPG needs to construct a user ID to identify your key. Real name: Hulk Lin # input your name Email address: hulk@apache.org # input your email Comment: # input some annotations, optional You selected this USER-ID: &quot;Hulk &lt;hulk@apache.org&gt;&quot; Change (N)ame, (C)omment, (E)mail or (O)kay/(Q)uit? O # input O We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilize the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy. We need to generate a lot of random bytes. It is a good idea to perform some other action (type on the keyboard, move the mouse, utilize the disks) during the prime generation; this gives the random number generator a better chance to gain enough entropy. # Input the security key ┌──────────────────────────────────────────────────────┐ │ Please enter this passphrase │ │ │ │ Passphrase: _______________________________ │ │ │ │ &lt;OK&gt; &lt;Cancel&gt; │ └──────────────────────────────────────────────────────┘ # key generation will be done after your inputting the key with the following output gpg: key E49B00F626B marked as ultimately trusted gpg: revocation certificate stored as '/Users/hulk/.gnupg/openpgp-revocs.d/F77B887A4F25A9468C513E9AA3008E49B00F626B.rev' public and secret key created and signed. pub rsa4096 2022-07-12 [SC] F77B887A4F25A9468C513E9AA3008E49B00F626B uid [ultimate] hulk &lt;hulk@apache.org&gt; sub rsa4096 2022-07-12 [E]   ","version":"Next","tagName":"h2"},{"title":"Upload your key to public GPG keyserver​","type":1,"pageTitle":"Setup GPG key","url":"/community/committers/reference/setup_gpg#upload-your-key-to-public-gpg-keyserver","content":" Firstly, list your key:  gpg --list-keys   The output is like:  ------------------------------- pub rsa4096 2022-07-12 [SC] F77B887A4F25A9468C513E9AA3008E49B00F626B uid [ultimate] hulk &lt;hulk@apache.org&gt; sub rsa4096 2022-07-12 [E]   Then, send your key id to key server:  gpg --keyserver keys.openpgp.org --send-key &lt;key-id&gt; # e.g., F77B887A4F25A9468C513E9AA3008E49B00F626B   Among them, keys.openpgp.org is a randomly selected keyserver, you can use keyserver.ubuntu.com or any other full-featured keyserver.  ","version":"Next","tagName":"h2"},{"title":"Check whether the key is created successfully​","type":1,"pageTitle":"Setup GPG key","url":"/community/committers/reference/setup_gpg#check-whether-the-key-is-created-successfully","content":" Uploading takes about one minute; after that, you can check by your email at the corresponding keyserver.  Uploading keys to the keyserver is mainly for joining a Web of Trust.  ","version":"Next","tagName":"h2"},{"title":"Add your GPG public key to the KEYS document​","type":1,"pageTitle":"Setup GPG key","url":"/community/committers/reference/setup_gpg#add-your-gpg-public-key-to-the-keys-document","content":" info SVN is required for this step.  The svn repository of the release branch is: https://dist.apache.org/repos/dist/release/opendal  Please always add the public key to KEYS in the release branch:  svn co https://dist.apache.org/repos/dist/release/opendal opendal-dist # As this step will copy all the versions, it will take some time. If the network is broken, please use svn cleanup to delete the lock before re-execute it. cd opendal-dist (gpg --list-sigs YOUR_NAME@apache.org &amp;&amp; gpg --export --armor YOUR_NAME@apache.org) &gt;&gt; KEYS # Append your key to the KEYS file svn add . # It is not needed if the KEYS document exists before. svn ci -m &quot;add gpg key for YOUR_NAME&quot; # Later on, if you are asked to enter a username and password, just use your apache username and password.   ","version":"Next","tagName":"h2"},{"title":"Upload the GPG public key to your GitHub account​","type":1,"pageTitle":"Setup GPG key","url":"/community/committers/reference/setup_gpg#upload-the-gpg-public-key-to-your-github-account","content":" Enter https://github.com/settings/keys to add your GPG key.Please remember to bind the email address used in the GPG key to your GitHub account (https://github.com/settings/emails) if you find &quot;unverified&quot; after adding it. ","version":"Next","tagName":"h2"},{"title":"Request for adding secrets","type":0,"sectionRef":"#","url":"/community/committers/request_for_adding_secrets","content":"Request for adding secrets OpenDAL's behavior tests depend on the secrets stored in 1password. If you want to sponsor any service, please email private@opendal.apache.org with the subject line Request to Add Secrets for &lt;service&gt;. Our PMC will review the request and reply to you. After the request is approved, you can use the secrets in the behavior tests when they are running on the GitHub Actions (You need to be a committer of OpenDAL). The email should also include the following information: The name of the serviceThe secrets in key-value pairs If the secrets have expiration dates, please also include the expiration dates. We may need you to update the secrets in the future. If the secrets are not under your control, please also include the contact information of the owner of the secrets. And finally, thank you for your support!","keywords":"","version":"Next"},{"title":"GSoC Project Proposal Guidance","type":0,"sectionRef":"#","url":"/community/events/gsoc-proposal-guide","content":"","keywords":"","version":"Next"},{"title":"Choosing a project​","type":1,"pageTitle":"GSoC Project Proposal Guidance","url":"/community/events/gsoc-proposal-guide#choosing-a-project","content":" You should start by deciding on which project do you want to work on. You can use our list of project ideasas an inspiration, or you can come up with your own project idea. However, you should keep in mind that each GSoC project needs at least one mentor available. Therefore, if you come up with a completely new project idea, you should also try to find someone from the OpenDAL community who could mentor you on the project.  If you decide to propose your own project idea, you're most likely to be able to find a mentor if you can describe clearly the utility of the project to OpenDAL community.  We encourage you to think of your own interesting project ideas! There are plenty of things that can be done within the OpenDAL project and contributors are generally happy to discuss and help you narrow down your thoughts into a concrete proposal. Don't be shy!  ","version":"Next","tagName":"h2"},{"title":"Interacting with the OpenDAL community​","type":1,"pageTitle":"GSoC Project Proposal Guidance","url":"/community/events/gsoc-proposal-guide#interacting-with-the-opendal-community","content":" If you want to discuss our suggested project ideas or your own idea, you can do so on the maillist or Discord. Make sure to listen to the feedback of the mentors, and try to incorporate it in your project proposal.  When communicating on the OpenDAL mail list or discord (and when interacting with the OpenDAL community in general), please remember to be polite and uphold the ASF Code of Conduct. Keep in mind that most OpenDAL contributors (and GSoC OpenDAL project mentors) are volunteers, and work on OpenDAL in their free time, so please treat them with respect and avoid spamming.  ","version":"Next","tagName":"h2"},{"title":"Creating the project proposal​","type":1,"pageTitle":"GSoC Project Proposal Guidance","url":"/community/events/gsoc-proposal-guide#creating-the-project-proposal","content":" Ultimately, the project proposal is the main deciding factor on whether your project will be accepted or not, so make sure that you put energy into making it as good as possible.  The proposal should contain (at least) the following things:  A descriptive title of the project that you want to work onInformation about yourself, including:  Description of your programming experience, attained education, university and study programme that you're currently studying, etc. (a short CV would be ideal)Link to a portfolio of projects that you have worked on (e.g. a GitHub profile or a personal website)Your knowledge of OpenDAL, since most projects will probably require at least some OpenDAL knowledgeYour existing open-source contribution experience. If you have already contributed to some open-source repositories, make sure to include a link to these contributions in your proposal!Your preferred time zone (for communicating with the mentor(s))Contact information  Information about your proposed project. This should be as detailed as possible, see more details below.Information about other commitments that might affect your ability to work on the project during the GSoC period. These can include vacations, exams, other jobs or internships etc. It's not necessarily an issue to have other commitments, but it would be great to know about them in advance, if possible.  ","version":"Next","tagName":"h2"},{"title":"Project information and timeline​","type":1,"pageTitle":"GSoC Project Proposal Guidance","url":"/community/events/gsoc-proposal-guide#project-information-and-timeline","content":" This is the most important part of your project proposal. You should include an abstract that explains your project in one or two paragraphs, and then a very detailed description that explains what exactly do you want to achieve in the proposed project. The proposal should also clearly state the designated mentor(s) for your project (you should get in touch with them before submitting the proposal).  In addition to describing what do you intend to work on in the project, you should also specify the size of the project, according to the GSoC documentation:  Small: ~90 hoursMedium: ~175 hoursLarge: ~350 hours  You should also create an approximate weekly plan of work and a list of deliverables. Recall that the default project duration is 12 weeks, but it can be extended (for medium and large projects) by up to 22 weeks.  Describe a brief outline of the work that you plan to do, and try to estimate how will the work be split in the individual weeks of the project.Define milestones that you intend to achieve in specific weeks (e.g. finish X in week 4, deliver Y in the middle of the project, have a final version prepared one week before the end of the project, etc.). You should focus specifically on the midterm point (week 6), because your mentor(s) will evaluate your progress at this time. You should be slightly more than half done at this moment, and have something reasonable to show.In week 11 (one week before the end of the project), you should consider doing a &quot;code freeze&quot;, and spend the last week to polish tests and documentation.  Of course, it is quite difficult to predict this timeline exactly in advance, and it is not a problem to modify it while the project runs, but try to guesstimate it to the best of your ability.  Furthermore, let us know what is your intended time commitment for working on the project. How many hours per day can you work on it? Are there specific days of the week when you can work on it? Is there some period of time from May to August where you know in advance that you won't be able to work on it? Please include this information in the proposal.  There is a Community bonding period before the contributors start working on their projects. It is designed to help you learn about the community that you're going to contribute to, and to start familiarizing yourself with the code and/or technology of your project. Please include a short description of preparatory work that you intend to work on during this community bonding period (should your project be accepted).  ","version":"Next","tagName":"h2"},{"title":"How to increase your chance of being accepted?​","type":1,"pageTitle":"GSoC Project Proposal Guidance","url":"/community/events/gsoc-proposal-guide#how-to-increase-your-chance-of-being-accepted","content":" You can demonstrate your dedication (and ability) to work on the selected project proposal by contributing something related to it before your proposal is evaluated. This can encompass e.g. sending a pull request to the relevant repository, fixing a bug, writing documentation, etc. There is no specific template for these kinds of contributions, and it might not be possible to do for all types of projects. You can coordinate with the project mentors to find out if they can suggest some entry-level task for you.  You can also tell us more about your motivation in your proposal. Why did you choose OpenDAL for a GSoC project specifically? Do you like the OpenDAL language? Is the specific project that you want to work on sympathetic to you for some reason? We would like to know!  ","version":"Next","tagName":"h2"},{"title":"Don't forget to submit!​","type":1,"pageTitle":"GSoC Project Proposal Guidance","url":"/community/events/gsoc-proposal-guide#dont-forget-to-submit","content":" You will need to submit your project proposal through the Google Summer of Code website. Please keep the deadline (2nd April 2024) in mind, as there will be no extensions!  Good luck! :)  ","version":"Next","tagName":"h2"},{"title":"How to decrease your chance of being accepted?​","type":1,"pageTitle":"GSoC Project Proposal Guidance","url":"/community/events/gsoc-proposal-guide#how-to-decrease-your-chance-of-being-accepted","content":" There are some actions and behaviours that will make it much less likely that your application will be considered, so you should avoid these. For example:  Spamming or harassing mentors or other members of the OpenDAL community.Letting AI automatically generate your project proposal (you should put effort in it, don't be lazy!).Suggesting unreasonably grandiose project proposals, e.g. adding a garbage collector to OpenDAL.Suggesting unreasonably trivial project proposals, e.g. fixing a typo in the OpenDAL documentation. Remember that even the smallest project size should take about 90 hours!  This guide was inspired by https://github.com/rust-lang/google-summer-of-code/blob/main/proposal-guide.md. ","version":"Next","tagName":"h2"},{"title":"Verify a release candidate","type":0,"sectionRef":"#","url":"/community/committers/verify","content":"","keywords":"","version":"Next"},{"title":"Download links are valid​","type":1,"pageTitle":"Verify a release candidate","url":"/community/committers/verify#download-links-are-valid","content":" To verify the release candidate, you need to download the release candidate from the dist directory.  Use the following command to download all artifacts, replace &quot;${release_version}-${rc_version}&quot; with the version ID of the version to be released:  svn co https://dist.apache.org/repos/dist/dev/opendal/${release_version}-${rc_version}/   ","version":"Next","tagName":"h2"},{"title":"Checksums and signatures​","type":1,"pageTitle":"Verify a release candidate","url":"/community/committers/verify#checksums-and-signatures","content":" The release candidate should have a checksum and signature file.  For example, if the release candidate is 0.45.0-rc1, the checksum and signature file should be:  https://dist.apache.org/repos/dist/dev/opendal/0.45.0-rc1/apache-opendal-0.45.0-rc1-src.tar.gz.sha512 https://dist.apache.org/repos/dist/dev/opendal/0.45.0-rc1/apache-opendal-0.45.0-rc1-src.tar.gz.asc   ","version":"Next","tagName":"h2"},{"title":"Verify checksums and signatures​","type":1,"pageTitle":"Verify a release candidate","url":"/community/committers/verify#verify-checksums-and-signatures","content":" GnuPG is recommended here. It can be installed with the following command:  apt-get install gnupg # or yum install gnupg # or brew install gnupg   Firstly, import the OpenDAL release manager's public key:  curl https://downloads.apache.org/opendal/KEYS &gt; KEYS # Download KEYS gpg --import KEYS # Import KEYS to local   Then, trust the public key:  gpg --edit-key &lt;KEY-used-in-this-version&gt; # Edit the key   It will enter the interactive mode, use the following command to trust the key:  gpg&gt; trust   And then, select the level of trust, for example:  Please decide how far you trust this user to correctly verify other users' keys (by looking at passports, checking fingerprints from different sources, etc.) 1 = I don't know or won't say 2 = I do NOT trust 3 = I trust marginally 4 = I trust fully 5 = I trust ultimately m = back to the main menu   Select 5 to trust the key ultimately.  Now, we could start the verification.  We've provided a script to verify the checksum and signature of the release candidate.  The script is in the scripts directory of our repository. You can download it directly from hereor check it out from the repository:  git clone https://github.com/apache/opendal   Run the script in a specific release candidate's folder:  ./scripts/verify.py   You will see the following output if the verification is successful:  gpg: Signature made Wed 21 Jul 2021 10:00:00 AM CST gpg: using RSA key 0x1234567890ABCDEF gpg: Good signature from &quot;Xuanwo&lt;xuanwo@apache.org&quot; [ultimate] gpg: WARNING: This key is not certified with a trusted signature! gpg: There is no indication that the signature belongs to the owner. Primary key fingerprint: 1234 5678 90AB CDEF 1234 5678 90AB CDEF 1234 5678 Success to verify the gpg sign apache-opendal-0.36.0-rc1-src.tar.gz: OK Success to verify the checksum   ","version":"Next","tagName":"h3"},{"title":"Check the file content of the source package​","type":1,"pageTitle":"Verify a release candidate","url":"/community/committers/verify#check-the-file-content-of-the-source-package","content":" Unzip apache-opendal-${release_version}-${rc_version}-src.tar.gz and check the follows:  LICENSE and NOTICE files are correct for the repository.All files have ASF license headers if necessary.Building is OK.  ","version":"Next","tagName":"h2"},{"title":"Check the Maven artifacts of opendal-java​","type":1,"pageTitle":"Verify a release candidate","url":"/community/committers/verify#check-the-maven-artifacts-of-opendal-java","content":" Download the artifacts from https://repository.apache.org/content/repositories/orgapacheopendal-${maven_artifact_number}/.  You can check the follows:  Checksum of JARs matches the bundled checksum file.Signature of JARs matches the bundled signature file.JARs is reproducible locally. This means you can build the JARs on your machine and verify the checksum is the same with the bundled one.  The reproducibility requires the same JDK distribution and the same Maven distribution. You should use Eclipse Temurin JDK 8 and the bundled Maven Wrapper to make the same artifacts. ","version":"Next","tagName":"h2"},{"title":"Maturity Assessment for Apache OpenDAL™","type":0,"sectionRef":"#","url":"/community/maturity","content":"","keywords":"","version":"Next"},{"title":"Status of this assessment​","type":1,"pageTitle":"Maturity Assessment for Apache OpenDAL™","url":"/community/maturity#status-of-this-assessment","content":" This assessment is still working in progress.  ","version":"Next","tagName":"h2"},{"title":"Maturity model assessment​","type":1,"pageTitle":"Maturity Assessment for Apache OpenDAL™","url":"/community/maturity#maturity-model-assessment","content":" The following table is filled according to the Apache Maturity Model. Mentors and community members are welcome to comment and modify it.  ","version":"Next","tagName":"h2"},{"title":"CODE​","type":1,"pageTitle":"Maturity Assessment for Apache OpenDAL™","url":"/community/maturity#code","content":" ID\tDescription\tStatusCD10\tThe project produces Open Source software for distribution to the public, at no charge.\tYES The project source code is licensed under the Apache License 2.0. CD20\tAnyone can easily discover and access the project's code..\tYES The official website includes GitHub link which can access the project's repository on GitHub directly. CD30\tAnyone using standard, widely-available tools, can build the code in a reproducible way.\tYES Apache OpenDAL provide how-to-build document for every component to tell user how to compile on bare metal, such as the core's. CD40\tThe full history of the project's code is available via a source code control system, in a way that allows anyone to recreate any released version.\tYES It depends on git, and anyone can view the full history of the project via commit logs. CD50\tThe source code control system establishes the provenance of each line of code in a reliable way, based on strong authentication of the committer. When third parties contribute code, commit messages provide reliable information about the code provenance.\tYES The project uses GitHub and managed by Apache Infra, it ensuring provenance of each line of code to a committer. And the third-party contributions are accepted in accordance with the contributing guides.  ","version":"Next","tagName":"h3"},{"title":"LICENSE​","type":1,"pageTitle":"Maturity Assessment for Apache OpenDAL™","url":"/community/maturity#license","content":" ID\tDescription\tStatusLC10\tThe Apache License, version 2.0, covers the released code.\tYES The LICENSE is in GitHub repository. And all source files are with APLv2 header, checked by korandoru/hawkeye@v3.6.0. LC20\tLibraries that are mandatory dependencies of the project's code do not create more restrictions than the Apache License does.\tYES All dependencies are listed. LC30\tThe libraries mentioned in LC20 are available as Open Source software.\tYES All dependencies are listed are available as Open Source software LC40\tCommitters are bound by an Individual Contributor Agreement (the &quot;Apache iCLA&quot;) that defines which code they may commit and how they need to identify code that is not their own.\tYES All committers have iCLAs. LC50\tThe project clearly defines and documents the copyright ownership of everything that the project produces.\tYES And all source files are with APLv2 header, checked by korandoru/hawkeye@v3.6.0.  ","version":"Next","tagName":"h3"},{"title":"Releases​","type":1,"pageTitle":"Maturity Assessment for Apache OpenDAL™","url":"/community/maturity#releases","content":" ID\tDescription\tStatusRE10\tReleases consist of source code, distributed using standard and open archive formats that are expected to stay readable in the long term.\tYES Source release is distributed via dist.apache.org and linked from download page. RE20\tThe project's PPMC (Project Management Committee, see CS10) approves each software release in order to make the release an act of the Foundation.\tYES All releases have been voted at dev@opendal.apache.org and general@incubator.apache.org, and have at least 3 PPMC member's votes. RE30\tReleases are signed and/or distributed along with digests that anyone can reliably use to validate the downloaded archives.\tYES All releases are signed, and the KEYS are available. RE40\tThe project can distribute convenience binaries alongside source code, but they are not Apache Releases, they are provided with no guarantee.\tYES User can easily build binaries from source code, and we do not provide binaries as Apache Releases. RE50\tThe project documents a repeatable release process so that someone new to the project can independently generate the complete set of artifacts required for a release.\tYES We can follow the Release guide to make a new Apache OpenDAL release, and so far we had 6 different release managers.  ","version":"Next","tagName":"h3"},{"title":"Quality​","type":1,"pageTitle":"Maturity Assessment for Apache OpenDAL™","url":"/community/maturity#quality","content":" ID\tDescription\tStatusQU10\tThe project is open and honest about the quality of its code. Various levels of quality and maturity for various modules are natural and acceptable as long as they are clearly communicated.\tYES We encourage user to report issues. QU20\tThe project puts a very high priority on producing secure software.\tYES All security issues will be addressed within 3 days. QU30\tThe project provides a well-documented, secure and private channel to report security issues, along with a documented way of responding to them.\tYes The official website provides a security page QU40\tThe project puts a high priority on backwards compatibility and aims to document any incompatible changes and provide tools and documentation to help users transition to new features.\tYes We follow semantic versions. As long as it's within one major version, it's backward compatible. And when any breaking changes added, we provide corresponding upgrade guides. QU50\tThe project strives to respond to documented bug reports in a timely manner.\tYES The project has resolved 1000+ issues and 2300+ pull requests so far, with very prompt response.  ","version":"Next","tagName":"h3"},{"title":"Community​","type":1,"pageTitle":"Maturity Assessment for Apache OpenDAL™","url":"/community/maturity#community","content":" ID\tDescription\tStatusCO10\tThe project has a well-known homepage that points to all the information required to operate according to this maturity model.\tYES The official website includes all information user need to run Apache OpenDAL. CO20\tThe community welcomes contributions from anyone who acts in good faith and in a respectful manner, and who adds value to the project.\tYes We provide contributing guides for every component. And we also have a general contributing guide CO30\tContributions include source code, documentation, constructive bug reports, constructive discussions, marketing and generally anything that adds value to the project.\tYES All good contributions including code and non-code are welcomed. CO40\tThe community strives to be meritocratic and gives more rights and responsibilities to contributors who, over time, add value to the project.\tYES The community has elected 2 new PPMC members and 7 new committers so far. CO50\tThe project documents how contributors can earn more rights such as commit access or decision power, and applies these principles consistently.\tYES The community has clear docs on nominating committers and PPMC members CO60\tThe community operates based on consensus of its members (see CS10) who have decision power. Dictators, benevolent or not, are not welcome in Apache projects.\tYES All decisions are made after vote by community members. CO70\tThe project strives to answer user questions in a timely manner.\tYES We use dev@opendal.apache.org, GitHub issue and GitHub discussion to do this in a timely manner.  ","version":"Next","tagName":"h3"},{"title":"Consensus​","type":1,"pageTitle":"Maturity Assessment for Apache OpenDAL™","url":"/community/maturity#consensus","content":" ID\tDescription\tStatusCS10\tThe project maintains a public list of its contributors who have decision power. The project's PPMC (Project Management Committee) consists of those contributors.\tYes See members with all PPMC members and committers. CS20\tDecisions require a consensus among PPMC members and are documented on the project's main communications channel. The PPMC takes community opinions into account, but the PPMC has the final word.\tYES All decisions are made by votes on dev@opendal.apache.org, and with at least 3 +1 votes from PPMC. CS30\tThe project uses documented voting rules to build consensus when discussion is not sufficient.\tYES The project uses the standard ASF voting rules. CS40\tIn Apache projects, vetoes are only valid for code commits. The person exercising the veto must justify it with a technical explanation, as per the Apache voting rules defined in CS30.\tYES Apache OpenDAL community has not used the veto power yet except for code commits. CS50\tAll &quot;important&quot; discussions happen asynchronously in written form on the project's main communications channel. Offline, face-to-face or private discussions that affect the project are also documented on that channel.\tYES All important discussions and conclusions are recorded in written form.  ","version":"Next","tagName":"h3"},{"title":"Independence​","type":1,"pageTitle":"Maturity Assessment for Apache OpenDAL™","url":"/community/maturity#independence","content":" ID\tDescription\tStatusIN10\tThe project is independent from any corporate or organizational influence.\tYES The PPMC members and committer of Apache OpenDAL are from several different companies, and majority of them are NOT From the company that donated this project. IN20\tContributors act as themselves, not as representatives of a corporation or organization.\tYES The contributors act on their own initiative without representing a corporation or organization. ","version":"Next","tagName":"h3"},{"title":"Create a release","type":0,"sectionRef":"#","url":"/community/committers/release","content":"","keywords":"","version":"Next"},{"title":"Introduction​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#introduction","content":" Source Release is the key point which Apache values, and is also necessary for an ASF release.  Please remember that publishing software has legal consequences.  This guide complements the foundation-wide policies and guides:  Release PolicyRelease Distribution PolicyRelease Creation Process  ","version":"Next","tagName":"h2"},{"title":"Some Terminology of release​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#some-terminology-of-release","content":" In the context of our release, we use several terms to describe different stages of the release process.  Here's an explanation of these terms:  opendal_version: the version of OpenDAL to be released, like 0.36.0.release_version: the version of release candidate, like 0.36.0-rc.1.rc_version: the minor version for voting round, like rc.1.maven_artifact_number: the number for Maven staging artifacts, like 1010. The number can be found by searching &quot;opendal&quot; on https://repository.apache.org/#stagingRepositories. And the Maven staging artifacts will be created automatically when we push a git tag to GitHub for now.  ","version":"Next","tagName":"h2"},{"title":"Preparation​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#preparation","content":" caution This section is the requirements for individuals who are new to the role of release manager.  Refer to Setup GPG Key to make sure the GPG key has been set up.  ","version":"Next","tagName":"h2"},{"title":"Start discussion about the next release​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#start-discussion-about-the-next-release","content":" Start a discussion about the next release via sending email to: dev@opendal.apache.org:  Title:  [DISCUSS] Release Apache OpenDAL ${release_version}   Content:  Hello, Apache OpenDAL Community, This is a call for a discussion to release Apache OpenDAL version ${opendal_version}. The change lists about this release: https://github.com/apache/opendal/compare/v${opendal_last_version}...main Please leave your comments here about this release plan. We will bump the version in the repo and start the release process after the discussion. Thanks ${name}   ","version":"Next","tagName":"h2"},{"title":"Start a tracking issue about the next release​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#start-a-tracking-issue-about-the-next-release","content":" Start a tracking issue on GitHub for the upcoming release to track all tasks that need to be completed.  Title:  Tracking issues of OpenDAL ${opendal_version} Release   Content:  This issue is used to track tasks of the opendal ${opendal_version} release. ## Tasks ### Blockers &gt; Blockers are the tasks that must be completed before the release. ### Build Release #### GitHub Side - [ ] Bump version in project - [ ] rust - [ ] cpp - [ ] haskell - [ ] java - [ ] nodejs - [ ] Update docs - [ ] Generate dependencies list - [ ] Push release candidate tag to GitHub #### ASF Side - [ ] Create an ASF Release - [ ] Upload artifacts to the SVN dist repo - [ ] Close the Nexus staging repo ### Voting - [ ] Start VOTE at opendal community ### Official Release - [ ] Push the release git tag - [ ] Publish artifacts to SVN RELEASE branch - [ ] Change OpenDAL Website download link - [ ] Release Maven artifacts - [ ] Send the announcement For details of each step, please refer to: https://opendal.apache.org/community/committers/release   ","version":"Next","tagName":"h2"},{"title":"GitHub Side​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#github-side","content":" ","version":"Next","tagName":"h2"},{"title":"Bump version in project​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#bump-version-in-project","content":" Bump all components' version in the project to the new opendal version. Please note that this version is the exact version of the release, not the release candidate version.  rust core: bump version in Cargo.tomlcpp binding: bump version in bindings/cpp/CMakeLists.txthaskell binding: bump version and update the tag field of source-repository this in bindings/haskell/opendal.cabaljava binding: bump version in bindings/java/pom.xmlnode.js binding: bump version in bindings/nodejs/package.json and bindings/nodejs/npm/*/package.json  ","version":"Next","tagName":"h3"},{"title":"Update docs​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#update-docs","content":" Update CHANGELOG.md, refer to Generate Release Note for more information.Update core/src/docs/upgrade.md if there are breaking changes in coreMake sure every released bindings' upgrade.md has been updated. java: bindings/java/upgrade.mdnode.js: bindings/nodejs/upgrade.mdpython: bindings/python/upgrade.md  ","version":"Next","tagName":"h3"},{"title":"Generate dependencies list​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#generate-dependencies-list","content":" Download and setup cargo-deny. You can refer to cargo-deny.  Running python3 ./scripts/dependencies.py generate to update the dependencies list of every package.  ","version":"Next","tagName":"h3"},{"title":"Push release candidate tag​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#push-release-candidate-tag","content":" After bump version PR gets merged, we can create a GitHub release for the release candidate:  Create a tag at main branch on the Bump Version / Patch up version commit: git tag -s &quot;v0.36.0-rc.1&quot;, please correctly check out the corresponding commit instead of directly tagging on the main branch.Push tags to GitHub: git push --tags.  note Pushing a Git tag to GitHub repo will trigger a GitHub Actions workflow that creates a staging Maven release on https://repository.apache.org which can be verified on voting.  ","version":"Next","tagName":"h3"},{"title":"Check the GitHub action status​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#check-the-github-action-status","content":" After pushing the tag, we need to check the GitHub action status to make sure the release candidate is created successfully.  Python: Bindings Python CIJava: Bindings Java CI and Bindings Java ReleaseNode.js: Bindings Node.js CI  In the most cases, it would be great to rerun the failed workflow directly when you find some failures. But if a new code patch is needed to fix the failure, you should create a new release candidate tag, increase the rc number and push it to GitHub.  ","version":"Next","tagName":"h3"},{"title":"ASF Side​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#asf-side","content":" If any step in the ASF Release process fails and requires code changes, we will abandon that version and prepare for the next one. Our release page will only display ASF releases instead of GitHub Releases.  Additionally, we should also drop the staging Maven artifacts on https://repository.apache.org.  ","version":"Next","tagName":"h2"},{"title":"Create an ASF Release​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#create-an-asf-release","content":" After GitHub Release has been created, we can start to create ASF Release.  Checkout to released tag. (e.g. git checkout v0.36.0-rc.1, tag is created in the previous step)Use the release script to create a new release: python ./scripts/release.py This script will generate the release candidate artifacts under dist, including: apache-opendal-{package}-{version}-src.tar.gzapache-opendal-{package}-{version}-src.tar.gz.ascapache-opendal-{package}-{version}-src.tar.gz.sha512 Push the newly created branch to GitHub  This script will create a new release under dist.  For example:  dist ├── apache-opendal-bindings-c-0.44.2+core.0.45.0-src.tar.gz ├── apache-opendal-bindings-c-0.44.2+core.0.45.0-src.tar.gz.asc ├── apache-opendal-bindings-c-0.44.2+core.0.45.0-src.tar.gz.sha512 ... ├── apache-opendal-core-0.45.0-src.tar.gz ├── apache-opendal-core-0.45.0-src.tar.gz.asc ├── apache-opendal-core-0.45.0-src.tar.gz.sha512 ├── apache-opendal-integrations-dav-server-0.0.0+core.0.45.0-src.tar.gz ├── apache-opendal-integrations-dav-server-0.0.0+core.0.45.0-src.tar.gz.asc ├── apache-opendal-integrations-dav-server-0.0.0+core.0.45.0-src.tar.gz.sha512 ├── apache-opendal-integrations-object_store-0.42.0+core.0.45.0-src.tar.gz ├── apache-opendal-integrations-object_store-0.42.0+core.0.45.0-src.tar.gz.asc └── apache-opendal-integrations-object_store-0.42.0+core.0.45.0-src.tar.gz.sha512 1 directory, 60 files   ","version":"Next","tagName":"h3"},{"title":"Upload artifacts to the SVN dist repo​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#upload-artifacts-to-the-svn-dist-repo","content":" info SVN is required for this step.  The svn repository of the dev branch is: https://dist.apache.org/repos/dist/dev/opendal  First, checkout OpenDAL to local directory:  # As this step will copy all the versions, it will take some time. If the network is broken, please use svn cleanup to delete the lock before re-execute it. svn co https://dist.apache.org/repos/dist/dev/opendal opendal-dist-dev   Then, upload the artifacts:  The ${release_version} here should be like 0.36.0-rc.1  cd opendal-dist-dev # create a directory named by version mkdir ${release_version} # copy source code and signature package to the versioned directory cp ${repo_dir}/dist/* ${release_version}/ # check svn status svn status # add to svn svn add ${release_version} # check svn status svn status # commit to SVN remote server svn commit -m &quot;Prepare for ${release_version}&quot;   Visit https://dist.apache.org/repos/dist/dev/opendal/ to make sure the artifacts are uploaded correctly.  ","version":"Next","tagName":"h3"},{"title":"Close the Nexus staging repo​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#close-the-nexus-staging-repo","content":" To verify the Maven staging artifacts in the next step, close the Nexus staging repo as below.  Open https://repository.apache.org/#stagingRepositories with your Apache ID login.Find the artifact orgapacheopendal-${maven_artifact_number}, click the &quot;Close&quot; button.  The close operation means that the artifacts are ready for voting.  caution If the vote failed, click &quot;Drop&quot; to drop the staging Maven artifacts.  ","version":"Next","tagName":"h3"},{"title":"Rescue​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#rescue","content":" If you accidentally published wrong or unexpected artifacts, like wrong signature files, wrong sha256 files, please cancel the release for the current release_version,increase th RC counting and re-initiate a release with the new release_version. And remember to delete the wrong artifacts from the SVN dist repo. Additionally, you should also drop the staging Maven artifacts on https://repository.apache.org.  ","version":"Next","tagName":"h3"},{"title":"Voting​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#voting","content":" OpenDAL requires votes from both the OpenDAL Community.  Vote should send email to: dev@opendal.apache.org:  Title:  [VOTE] Release Apache OpenDAL ${release_version} - Vote Round 1   Content:  Hello, Apache OpenDAL Community, This is a call for a vote to release Apache OpenDAL version ${opendal_version}. The tag to be voted on is ${opendal_version}. The release candidate: https://dist.apache.org/repos/dist/dev/opendal/${release_version}/ Keys to verify the release candidate: https://downloads.apache.org/opendal/KEYS Git tag for the release: https://github.com/apache/opendal/releases/tag/v${release_version} Maven staging repo: https://repository.apache.org/content/repositories/orgapacheopendal-${maven_artifact_number}/ Pypi testing repo: https://test.pypi.org/project/opendal/ Please download, verify, and test. The VOTE will be open for at least 72 hours and until the necessary number of votes are reached. [ ] +1 approve [ ] +0 no opinion [ ] -1 disapprove with the reason To learn more about apache opendal, please see https://opendal.apache.org/ Checklist for reference: [ ] Download links are valid. [ ] Checksums and signatures. [ ] LICENSE/NOTICE files exist [ ] No unexpected binary files [ ] All source files have ASF headers [ ] Can compile from source Use our verify.py to assist in the verify process: svn co https://dist.apache.org/repos/dist/dev/opendal/${release_version}/ opendal-dev cd opendal-dev curl -sSL https://github.com/apache/opendal/raw/v${release_version}/scripts/verify.py -o verify.py python verify.py Thanks ${name}   Example: https://lists.apache.org/thread/c211gqq2yl15jbxqk4rcnq1bdqltjm5l  The vote should be open for at least 72 hours except the following cases:  Security issuesThe wild user effected bug fixesAny other emergency cases  The Release manager should claim the emergency cases in the vote email if he want to vote it rapidly.  Tips: The 72 hours is the minimum time for voting, so we can ensure that community members from various time zones can participate in the verification process.  After at least 3 +1 binding vote (from OpenDAL Podling PMC member) and no veto, claim the vote result:  Title:  [RESULT][VOTE] Release Apache OpenDAL ${release_version} - Vote Round 1   Content:  Hello, Apache OpenDAL Community, The vote to release Apache OpenDAL ${release_version} has passed. The vote PASSED with 3 +1 binding and 1 +1 non-binding votes, no +0 or -1 votes: Binding votes: - xxx - yyy - zzz Non-Binding votes: - aaa Vote thread: ${vote_thread_url} Thanks ${name}   It's better to use the real name or the public name which is displayed on the voters' profile page, or Apache ID of the voter, to show who voted in the vote result email, and avoid using nicknames, it will make the vote result hard for others to track the voter. We should make sure the binding votes are from the people who have the right to vote the binding one.  Example: https://lists.apache.org/thread/xk5myl10mztcfotn59oo59s4ckvojds6  ","version":"Next","tagName":"h2"},{"title":"Official Release​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#official-release","content":" ","version":"Next","tagName":"h2"},{"title":"Push the release git tag​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#push-the-release-git-tag","content":" # Checkout the tags that passed VOTE git checkout ${release_version} # Tag with the opendal version git tag -s ${opendal_version} # Push tags to GitHub to trigger releases git push origin ${opendal_version}   ","version":"Next","tagName":"h3"},{"title":"Publish artifacts to SVN RELEASE branch​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#publish-artifacts-to-svn-release-branch","content":" svn mv https://dist.apache.org/repos/dist/dev/opendal/${release_version} https://dist.apache.org/repos/dist/release/opendal/${opendal_version} -m &quot;Release ${opendal_version}&quot;   ","version":"Next","tagName":"h3"},{"title":"Change OpenDAL Website download link​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#change-opendal-website-download-link","content":" Change the download link in the website to the new release version.  Update the latest release link and add the new release link to the version list.  Take Add 0.39.0 release link to download.md as an example.  ","version":"Next","tagName":"h3"},{"title":"Release Maven artifacts​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#release-maven-artifacts","content":" Open https://repository.apache.org/#stagingRepositories.Find the artifact orgapacheopendal-${maven_artifact_number}, click the &quot;Release&quot; button.  It will take some time to sync the Maven artifacts to the Maven Central.  caution If the vote failed, click &quot;Drop&quot; to drop the staging Maven artifacts.  ","version":"Next","tagName":"h3"},{"title":"Check the language binding artifacts​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#check-the-language-binding-artifacts","content":" We need to check the language binding artifacts in the language package repo to make sure they are released successfully.  Python: https://pypi.org/project/opendal/Java: https://repository.apache.org/#nexus-search;quick~opendalNode.js: https://www.npmjs.com/package/opendal  For Java binding, if we can not find the latest version of artifacts in the repo, we need to check the orgapacheopendal-${maven_artifact_number} artifact status in staging repo.  For non-Java bindings, if we can not find the latest version of artifacts in the repo, we need to check the GitHub action status.  ","version":"Next","tagName":"h3"},{"title":"Create a GitHub Release​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#create-a-github-release","content":" Click here to create a new release.Pick the git tag of this release version from the dropdown menu.Make sure the branch target is main.Generate the release note by clicking the Generate release notes button.Add the release note from every component's upgrade.md if there are breaking changes before the content generated by GitHub. Check them carefully.Publish the release.  ","version":"Next","tagName":"h3"},{"title":"Send the announcement​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#send-the-announcement","content":" Send the release announcement to dev@opendal.apache.org and CC announce@apache.org.  Tips: Please following the Committer Email guide to make sure you have already set up the email SMTP. Otherwise, your email cannot be sent to the announcement mailing list.  Instead of adding breaking changes, let's include the new features as &quot;notable changes&quot; in the announcement.  Title:  [ANNOUNCE] Release Apache OpenDAL ${opendal_version}   Content:  Hi all, The Apache OpenDAL community is pleased to announce that Apache OpenDAL ${opendal_version} has been released! OpenDAL is a data access layer that allows users to easily and efficiently retrieve data from various storage services in a unified way. The notable changes since ${opendal_version} include: 1. xxxxx 2. yyyyyy 3. zzzzzz Please refer to the change log for the complete list of changes: https://github.com/apache/opendal/releases/tag/v${opendal_version} Apache OpenDAL website: https://opendal.apache.org/ Download Links: https://opendal.apache.org/download OpenDAL Resources: - Issue: https://github.com/apache/opendal/issues - Mailing list: dev@opendal.apache.org Thanks On behalf of Apache OpenDAL community   Example: https://lists.apache.org/thread/oy77n55brvk72tnlb2bjzfs9nz3cfd0s  ","version":"Next","tagName":"h3"},{"title":"Post release​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#post-release","content":" After the official release out, you may perform a few post actions.  ","version":"Next","tagName":"h2"},{"title":"Remove the old releases​","type":1,"pageTitle":"Create a release","url":"/community/committers/release#remove-the-old-releases","content":" Remove the old releases if any. You only need the latest release there, and older releases are available through the Apache archive.  To clean up old releases, run:  # 1. Get the list of releases svn ls https://dist.apache.org/repos/dist/release/opendal # 2. Delete each release (except for the last one) svn del -m &quot;Archiving OpenDAL release X.Y.Z&quot; https://dist.apache.org/repos/dist/release/opendal/X.Y.Z  ","version":"Next","tagName":"h3"},{"title":"Nominate Committer","type":0,"sectionRef":"#","url":"/community/pmc_members/nominate-committer","content":"","keywords":"","version":"Next"},{"title":"Start vote about the candidate​","type":1,"pageTitle":"Nominate Committer","url":"/community/pmc_members/nominate-committer#start-vote-about-the-candidate","content":" Start a vote about the candidate via sending email to: private@opendal.apache.org:  candidate_name: The full name of the candidate.candidate_github_id: The GitHub id of the candidate.  Title:  [VOTE] Add candidate ${candidate_name} as a new committer   Content:  Hi, All OpenDAL PMC members. I'd like to take this chance to call the vote for inviting committed contributor ${candidate_name} (GitHub id: ${candidate_github_id}) as a new committer of Apache OpenDAL. ${candidate_contributions} ${candidate_name}'s great contributions could be found: - Github Account: https://github.com/${candidate_github_id} - Github Pull Requests: https://github.com/apache/opendal/pulls?q=is%3Apr+author%3A${candidate_github_id}+is%3Aclosed - Github Issues: https://github.com/apache/opendal/issues?q=is%3Aopen+mentions%3A${candidate_github_id} Please make your valuable evaluation on whether we could invite ${candidate_name} as a committer: [ +1 ] Agree to add ${candidate_name} as a committer of OpenDAL. [ 0 ] Have no sense. [ -1 ] Disagree to add ${candidate_name} as a committer of OpenDAL, because ..... This vote starts from the moment of sending and will be open for 3 days. Thanks and best regards, ${your_name}   Example: https://lists.apache.org/thread/j16lvkyrmvg8wyf3z4gqpjky5m594jhy (Private Link)  After at least 3 +1 binding vote and no veto, claim the vote result:  Title:  [RESULT][VOTE] Add candidate ${candidate_name} as a new committer   Content:  Hi, all: The vote for &quot;Add candidate ${candidate_name} as a new committer&quot; has PASSED and closed now. The result is as follows: 4 binding +1 Votes: - voter names Vote thread: https://lists.apache.org/thread/j16lvkyrmvg8wyf3z4gqpjky5m594jhy Then I'm going to invite ${candidate_name} to join us. Thanks for everyone's support! ${your_name}   ","version":"Next","tagName":"h2"},{"title":"Send invitation to the candidate​","type":1,"pageTitle":"Nominate Committer","url":"/community/pmc_members/nominate-committer#send-invitation-to-the-candidate","content":" Send an invitation to the candidate and cc private@opendal.apache.org:  Title:  Invitation to become OpenDAL Committer: ${candidate_name}   Content:  Hello ${candidate_name}, The OpenDAL PMC hereby offers you committer privileges to the project. These privileges are offered on the understanding that you'll use them reasonably and with common sense. We like to work on trust rather than unnecessary constraints. Being a committer enables you to more easily make changes without needing to go through the patch submission process. Being a committer does not require you to participate any more than you already do. It does tend to make one even more committed. You will probably find that you spend more time here. Of course, you can decline and instead remain as a contributor, participating as you do now. A. This personal invitation is a chance for you to accept or decline in private. Either way, please let us know in reply to the [private@opendal.apache.org] address only. B. If you accept, the next step is to register an iCLA: 1. Details of the iCLA and the forms are found through this link: https://www.apache.org/licenses/#clas 2. Instructions for its completion and return to the Secretary of the ASF are found at https://www.apache.org/licenses/#submitting 3. When you transmit the completed iCLA, request to notify the Apache OpenDAL and choose a unique Apache ID. Look to see if your preferred ID is already taken at https://people.apache.org/committer-index.html This will allow the Secretary to notify the PMC when your iCLA has been recorded. When recording of your iCLA is noted, you will receive a follow-up message with the next steps for establishing you as a committer. With the expectation of your acceptance, welcome! ${your_name} (as represents of The Apache OpenDAL PMC)   ","version":"Next","tagName":"h2"},{"title":"Add the candidate to the committer list​","type":1,"pageTitle":"Nominate Committer","url":"/community/pmc_members/nominate-committer#add-the-candidate-to-the-committer-list","content":" After the candidate accepts the invitation and the iCLA is recorded, add the candidate to the committer list by whimsy roster tools   ","version":"Next","tagName":"h2"},{"title":"News","type":0,"sectionRef":"#","url":"/community/news","content":"News 2024-02-05: Apache OpenDAL 0.45.0 released. RM=Morris Tai2024-01-23: New Committer, Yang Shuai @hoslo2024-01-22: New PMC Member, Liuqing Yue @dqhl762024-01-21: Apache OpenDAL 0.44.2 released. RM=Zheao Li2024-01-18: Apache OpenDAL Graduated2024-01-12: New Committer, Wenkang Xu @WenyXu.2024-01-06: Apache OpenDAL (incubating) 0.44.1 released. RM=Hao Ding2024-01-01: New Committer, Congyi Wang @wcy-fdu.2023-12-31: Apache OpenDAL (incubating) 0.44.0 released. RM=Liuqing Yue2023-12-11: New PPMC Member, Xiangdong @G-XD.2023-12-08: Apache OpenDAL (incubating) 0.43.0 released. RM=Xiangdong2023-11-29: New Committer, Morris Tai @morristai.2023-11-16: Apache OpenDAL (incubating) 0.42.0 released. RM=Mingzhuo Yin2023-09-22: New Committer, Zheao Li @Zheaoli.2023-10-16: Apache OpenDAL (incubating) 0.41.0 released. RM=Han Xu2023-09-22: New Committer, Xiangdong @G-XD.2023-09-21: Apache OpenDAL (incubating) 0.40.0 released. RM=Ding Hao2023-09-08: New PPMC Member, Mingzhuo Yin @silver-ymz.2023-08-30: New Committer, Dongyang Zheng @Young-Flash.2023-08-19: New Committer, Liuqing Yue @dqhl76.2023-07-31: Apache OpenDAL (incubating) 0.39.0 released. RM=Jun Ouyang2023-07-15: Apache OpenDAL (incubating) 0.38.1 released. RM=Cai Lue2023-07-15: New Committer, Jun Ouyang @oowl.2023-06-28: Apache OpenDAL (incubating) 0.38.0 released. RM=Zhuoran Shang2023-06-16: New Committer, Mingzhuo Yin @silver-ymz.2023-06-06: Apache OpenDAL (incubating) 0.37.0 released. RM=Han Xu2023-05-30: Apache OpenDAL (incubating) 0.36.0 released. RM=Ding Hao2023-05-29: New Committer, Xinyou Ji @Ji-Xinyou.2023-04-21: New PPMC Member, Han Xu @suyanhanx.2023-03-20: New Committer, Lusheng Lyu @messense.2023-03-20: New Committer, Han Xu @suyanhanx.2023-02-27: Project enters incubation.","keywords":"","version":"Next"},{"title":"Nominate PMC Member","type":0,"sectionRef":"#","url":"/community/pmc_members/nominate-pmc-member","content":"","keywords":"","version":"Next"},{"title":"Start vote about the candidate​","type":1,"pageTitle":"Nominate PMC Member","url":"/community/pmc_members/nominate-pmc-member#start-vote-about-the-candidate","content":" Start a vote about the candidate via sending email to: private@opendal.apache.org:  candidate_name: The full name of the candidate.candidate_github_id: The GitHub id of the candidate.  Title:  [VOTE] Add candidate ${candidate_name} as a new PMC member   Content:  Hi, All OpenDAL PMC members. I would like to nominate ${candidate_name} (GitHub id: ${candidate_github_id}) as a candidate for the OpenDAL PMC member. Since becoming an OpenDAL committer, ${candidate_name} has made significant contributions to various modules of the project. ${candidate_name}'s great contributions could be found: - Github Account: https://github.com/${candidate_github_id} - Github Pull Requests: https://github.com/apache/opendal/pulls?q=is%3Apr+author%3A${candidate_github_id}+is%3Aclosed - Github Issues: https://github.com/apache/opendal/issues?q=is%3Aopen+mentions%3A${candidate_github_id} Please make your valuable evaluation on whether we could invite ${candidate_name} as a PMC member: [ +1 ] Agree to add ${candidate_name} as a PMC member of OpenDAL. [ 0 ] Have no sense. [ -1 ] Disagree to add ${candidate_name} as a PMC member of OpenDAL, because ..... This vote starts from the moment of sending and will be open for 3 days. Thanks and best regards, ${your_name}   Example: https://lists.apache.org/thread/yg2gz2tof3cvbrgp1wxzk6mf9o858h7t (Private Link)  After at least 3 +1 binding vote and no veto, claim the vote result:  Title:  [RESULT][VOTE] Add candidate ${candidate_name} as a new PMC member   Content:  Hi, all: The vote for &quot;Add candidate ${candidate_name} as a new PMC member&quot; has PASSED and closed now. The result is as follows: 4 binding +1 Votes: - voter names Vote thread: https://lists.apache.org/thread/yg2gz2tof3cvbrgp1wxzk6mf9o858h7t Then I'm going to invite ${candidate_name} to join us. Thanks for everyone's support! ${your_name}   ","version":"Next","tagName":"h2"},{"title":"Send NOTICE to Board after VOTE PASSED​","type":1,"pageTitle":"Nominate PMC Member","url":"/community/pmc_members/nominate-pmc-member#send-notice-to-board-after-vote-passed","content":" The nominating PMC member should send a message to the Board board@apache.org with a reference to the vote result in the following form:  Title:  [NOTICE] ${candidate_name} for Apache OpenDAL PMC   Content:  ${candidate_name} has been voted as a new member of the Apache OpenDAL PMC. the vote thread is at: https://lists.apache.org/thread/yg2gz2tof3cvbrgp1wxzk6mf9o858h7t   ","version":"Next","tagName":"h2"},{"title":"Send invitation to the candidate​","type":1,"pageTitle":"Nominate PMC Member","url":"/community/pmc_members/nominate-pmc-member#send-invitation-to-the-candidate","content":" Send an invitation to the candidate and cc private@opendal.apache.org:  Title:  Invitation to become Apache OpenDAL PMC Member: ${candidate_name}   Content:  Hello ${candidate_name}, In recognition of your contributions to Apache OpenDAL, the OpenDAL PMC has recently voted to add you as a PMC member. The role of a PMC member grants you access to the Project Management Committee (PMC) and enables you to take on greater responsibilities within the OpenDAL project. We hope that you accept this invitation and continue to help us make Apache OpenDAL better. Please reply to private@opendal.apache.org using the 'reply all' function for your responses. With the expectation of your acceptance, welcome! ${your_name} (as represents of The Apache OpenDAL PMC)   ","version":"Next","tagName":"h2"},{"title":"Add the candidate to the PMC member list​","type":1,"pageTitle":"Nominate PMC Member","url":"/community/pmc_members/nominate-pmc-member#add-the-candidate-to-the-pmc-member-list","content":" After the candidate accepts the invitation, add the candidate to the PMC member list by whimsy roster tools   ","version":"Next","tagName":"h2"},{"title":"Onboarding","type":0,"sectionRef":"#","url":"/community/pmc_members/onboarding","content":"","keywords":"","version":"Next"},{"title":"Subscribe to Private Mailing List​","type":1,"pageTitle":"Onboarding","url":"/community/pmc_members/onboarding#subscribe-to-private-mailing-list","content":" Send email to private-subscribe@opendal.apache.orgYou will receive an email with the subject &quot;confirm subscribe to private@opendal.apache.org&quot;Reply to the email with &quot;Confirm&quot; in the body  If you receive an email with the subject &quot;WELCOME to private@opendal.apache.org&quot;, you have successfully subscribed to the private mailing list.  It's required for PMC members to subscribe the private mailing list. The private list is only for confidential discussions that should not be made public, such as the suitability of a particular individual to become a committer or a member of the PMC.  ","version":"Next","tagName":"h2"},{"title":"Setup 1Password Secrets Access​","type":1,"pageTitle":"Onboarding","url":"/community/pmc_members/onboarding#setup-1password-secrets-access","content":" Once you have been added to OpenDAL's PMC member list, you will gain the access to all OpenDAL's secrets.  Please refrain from modifying secrets in the Services vault as this could disrupt our integration tests.Ensure that you keep all secrets secure and avoid sharing them with others or making them public. Do not commit them anywhere else.  ","version":"Next","tagName":"h2"},{"title":"Read PMC Member Guide​","type":1,"pageTitle":"Onboarding","url":"/community/pmc_members/onboarding#read-pmc-member-guide","content":" Please read PMC GUIDE to know about the general responsibilities of Project Management Committee (PMC) members in managing our project and common how-to procedures for day to day maintenance. ","version":"Next","tagName":"h2"},{"title":"Podling Status Reports","type":0,"sectionRef":"#","url":"/community/pmc_members/podling-report","content":"","keywords":"","version":"Next"},{"title":"Frequency of Reporting​","type":1,"pageTitle":"Podling Status Reports","url":"/community/pmc_members/podling-report#frequency-of-reporting","content":" New podlings are required to submit reports monthly for the first three months. After this period, the reporting frequency changes to quarterly.  The current reporting frequency for Apache OpenDAL™ is once per quarter. Stay attentive to general@incubator.apache.org (subscribe), where due dates for these reports are announced.  ","version":"Next","tagName":"h3"},{"title":"Report Preparation​","type":1,"pageTitle":"Podling Status Reports","url":"/community/pmc_members/podling-report#report-preparation","content":" It's recommended to discuss the report on dev@opendal.apache.org (subscribe), inviting all members to contribute. Here are the critical points your report should address:  Any concerns that require the attention of the Incubator PMC or ASF Board.Legal, infrastructure, cross-project, or personal issues that need addressing.Achievements (releases, milestones, etc.) since the last report.The activity and helpfulness of mentors.Any other significant points or thoughts you think should be included.  You can discuss the issues based on the template or refer to previous reports for preparation.  ","version":"Next","tagName":"h3"},{"title":"Report Writing and Submission​","type":1,"pageTitle":"Podling Status Reports","url":"/community/pmc_members/podling-report#report-writing-and-submission","content":" Podling Status Report has its own format. Please fill it out based on your assessment of the project's incubation status and the materials collected during the preparation phase. We should use the existing format and don’t change the subject headers.  note Note that IPMC update the template from time to time, so be sure to use the one IPMC provide and not a previous report.  ","version":"Next","tagName":"h3"},{"title":"Mentor Sign-off​","type":1,"pageTitle":"Podling Status Reports","url":"/community/pmc_members/podling-report#mentor-sign-off","content":" Each Podling Status Report must be signed off by a mentor. Without a mentor's sign-off, the IPMC will not accept the report, and the podling will need to submit a new report the following month.  After submitting the report, you can email dev@opendal.apache.org to remind our mentors and the community to review the report and provide feedback.  [ANNOUNCE] OpenDAL's Podling Report of &lt;Month&gt;&lt;Year&gt; Hello, everyone! As a representative of the OpenDAL community, I am pleased to present our &lt;Month&gt;&lt;Year&gt; podling report. We appreciate the opportunity to share updates on our progress and achievements over the past weeks, and we welcome any feedback or suggestions that may help us continue to grow and succeed as a project. Thank you for your continued support. LINK: &lt;link-of-report-in-cwiki&gt;  ","version":"Next","tagName":"h3"},{"title":"Security","type":0,"sectionRef":"#","url":"/community/security","content":"Security The Apache Software Foundation takes a rigorous stance on eliminating security issues in its software projects. Likewise, Apache OpenDAL™ is also vigilant and takes security issues related to its features and functionality into the highest consideration. If you have any concerns regarding OpenDAL's security, or you discover a vulnerability or potential threat, please do not hesitate to get in touch with the Apache Security Team by dropping an email at private@opendal.apache.org. Please specify the project name as &quot;OpenDAL&quot; in the email, and provide a description of the relevant problem or potential threat. You are also urged to recommend how to reproduce and replicate the issue. The Apache Security Team and the OpenDAL community will get back to you after assessing and analyzing the findings. Please note that the security issue should be reported on the security email first, before disclosing it on any public domain.","keywords":"","version":"Next"},{"title":"dav-server-opendalfs","type":0,"sectionRef":"#","url":"/docs/integrations/dav-server-opendalfs","content":"dav-server-opendalfs dav-server-opendalfs dav-server-opendalfs is an integration which uses OpenDAL as a backend to access data in various service with WebDAV protocol.","keywords":"","version":"Next"},{"title":"object_store_opendal","type":0,"sectionRef":"#","url":"/docs/integrations/object_store_opendal","content":"object_store_opendal object_store_opendal is an integration which uses OpenDAL as a backend for the object_store. OpenDAL object_store Binding This crate intends to build an object_store binding.","keywords":"","version":"Next"},{"title":"Welcome to Apache OpenDAL™","type":0,"sectionRef":"#","url":"/docs/overview","content":"","keywords":"","version":"Next"},{"title":"What does OpenDAL do?​","type":1,"pageTitle":"Welcome to Apache OpenDAL™","url":"/docs/overview#what-does-opendal-do","content":"   ","version":"Next","tagName":"h2"},{"title":"Getting started​","type":1,"pageTitle":"Welcome to Apache OpenDAL™","url":"/docs/overview#getting-started","content":" See the page for quick start with multiple languages: Quickstart.  ","version":"Next","tagName":"h2"},{"title":"Why OpenDAL?​","type":1,"pageTitle":"Welcome to Apache OpenDAL™","url":"/docs/overview#why-opendal","content":" The vision of OpenDAL is access data freely, where &quot;free&quot; refers to four essential aspects:  ","version":"Next","tagName":"h2"},{"title":"1. Free from services​","type":1,"pageTitle":"Welcome to Apache OpenDAL™","url":"/docs/overview#1-free-from-services","content":" OpenDAL must enable users to access various storage services ranging from s3 to dropbox via its own native API. It should provide a unified API for accessing all these services.  For example, we DO  Add support for Google Drive: It allows users to access and manage their data on the Google Drive.Add support for Object Storage Service (OSS) via native API: Users can utilize Aliyun's RAM support.Add support for supabase storage: Users can visit supabase storage now!  while we DO NOT  Add support for Google Cloud Storage (GCS) via XML API: GCS has native JSON API which is more powerfulAdd support for structural data in MySQL/PostgreSQL: We can treat a database as a simple key-value store, but we can't support unified access of structural data.  ","version":"Next","tagName":"h3"},{"title":"2. Free from implementations​","type":1,"pageTitle":"Welcome to Apache OpenDAL™","url":"/docs/overview#2-free-from-implementations","content":" OpenDAL needs to separate the various implementation details of services and enables users to write identical logic for different services.  For example, we DO  Add a new capability to indicate whether presign is supported: Users can now write logic based on the can_presign option.Add a default_storage_class configuration for the S3 service: Configuration is specific to the S3 service.Add an option for content_type in the write operation: It aligns with HTTP standards.  while we DO NOT  Add a new option in read for storage_class: As different services could have varying values for this parameter.  ","version":"Next","tagName":"h3"},{"title":"3. Free to integrate​","type":1,"pageTitle":"Welcome to Apache OpenDAL™","url":"/docs/overview#3-free-to-integrate","content":" OpenDAL needs to be integrated with different systems.  For example, we DO  Add Python binding: Python programmers can use OpenDAL.Add object_store integration: object_store users can adopt OpenDAL.  ","version":"Next","tagName":"h3"},{"title":"4. Free of cost​","type":1,"pageTitle":"Welcome to Apache OpenDAL™","url":"/docs/overview#4-free-of-cost","content":" OpenDAL needs to implement features in a zero cost way which means:  Users don't need to pay costs for unused features.Users cannot write better implementation for used features.  For example, we DO  Add layer support: Users can add logging/metrics/tracing in zero cost way.Implement seek for Reader: Users cannot write better seek support, they all need to pay the same cost.  we DO NOT  Add Arc for metadata: Users may only need to use metadata once and never clone it. For those who do want this feature, they can add Arc themselves. ","version":"Next","tagName":"h3"},{"title":"AtomicServer","type":0,"sectionRef":"#","url":"/docs/services/atomicserver","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"AtomicServer","url":"/docs/services/atomicserver#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"AtomicServer","url":"/docs/services/atomicserver#configuration","content":" root: Set the working directory of OpenDALendpoint: Set the server address for Atomicserverprivate_key: Set the private key for agent used for Atomicserverpublic_key: Set the public key for agent used for Atomicserverparent_resource_id: Set the parent resource id (url) that Atomicserver uses to store resources under  You can refer to [AtomicserverBuilder]'s docs for more information.  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"AtomicServer","url":"/docs/services/atomicserver#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"AtomicServer","url":"/docs/services/atomicserver#via-builder","content":" use anyhow::Result; use opendal::services::Atomicserver; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Atomicserver::default(); // Set the server address for Atomicserver builder.endpoint(&quot;http://localhost:9883&quot;); // Set the public/private key for agent for Atomicserver builder.private_key(&quot;&lt;private_key&gt;&quot;); builder.public_key(&quot;&lt;public_key&gt;&quot;); // Set the parent resource id for Atomicserver. In this case // We are using the root resource (Drive) builder.parent_resource_id(&quot;http://localhost:9883&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"AtomicServer","url":"/docs/services/atomicserver#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::services::Sqlite; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;endpoint&quot;.to_string(), &quot;http://localhost:9883&quot;.to_string()); map.insert(&quot;private_key&quot;.to_string(), &quot;your_private_key&quot;.to_string()); map.insert(&quot;public_key&quot;.to_string(), &quot;your_public_key&quot;.to_string()); map.insert(&quot;parent_resource_id&quot;.to_string(), &quot;your_resource_id&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Atomicserver, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Azblob","type":0,"sectionRef":"#","url":"/docs/services/azblob","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Azblob","url":"/docs/services/azblob#capabilities","content":" This service can be used to:   stat read write append create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Azblob","url":"/docs/services/azblob#configuration","content":" root: Set the work dir for backend.container: Set the container name for backend.endpoint: Set the endpoint for backend.account_name: Set the account_name for backend.account_key: Set the account_key for backend.  Refer to public API docs for more information.  ","version":"Next","tagName":"h2"},{"title":"Examples​","type":1,"pageTitle":"Azblob","url":"/docs/services/azblob#examples","content":" This example works on Azurite for local developments.  ","version":"Next","tagName":"h2"},{"title":"Start local blob service​","type":1,"pageTitle":"Azblob","url":"/docs/services/azblob#start-local-blob-service","content":" docker run -p 10000:10000 mcr.microsoft.com/azure-storage/azurite az storage container create --name test --connection-string &quot;DefaultEndpointsProtocol=http;AccountName=devstoreaccount1;AccountKey=Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==;BlobEndpoint=http://127.0.0.1:10000/devstoreaccount1;&quot;   ","version":"Next","tagName":"h3"},{"title":"Init OpenDAL Operator​","type":1,"pageTitle":"Azblob","url":"/docs/services/azblob#init-opendal-operator","content":" ","version":"Next","tagName":"h3"},{"title":"Via Builder​","type":1,"pageTitle":"Azblob","url":"/docs/services/azblob#via-builder","content":" use std::sync::Arc; use anyhow::Result; use opendal::services::Azblob; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // Create azblob backend builder. let mut builder = Azblob::default(); // Set the root for azblob, all operations will happen under this root. // // NOTE: the root must be absolute path. builder.root(&quot;/path/to/dir&quot;); // Set the container name, this is required. builder.container(&quot;test&quot;); // Set the endpoint, this is required. // // For examples: // - &quot;http://127.0.0.1:10000/devstoreaccount1&quot; // - &quot;https://accountname.blob.core.windows.net&quot; builder.endpoint(&quot;http://127.0.0.1:10000/devstoreaccount1&quot;); // Set the account_name and account_key. // // OpenDAL will try load credential from the env. // If credential not set and no valid credential in env, OpenDAL will // send request without signing like anonymous user. builder.account_name(&quot;devstoreaccount1&quot;); builder.account_key(&quot;Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==&quot;); // `Accessor` provides the low level APIs, we will use `Operator` normally. let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Azblob","url":"/docs/services/azblob#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); map.insert(&quot;container&quot;.to_string(), &quot;test&quot;.to_string()); map.insert(&quot;endpoint&quot;.to_string(), &quot;http://127.0.0.1:10000/devstoreaccount1&quot;.to_string()); map.insert(&quot;account_name&quot;.to_string(), &quot;devstoreaccount1&quot;.to_string()); map.insert(&quot;account_key&quot;.to_string(), &quot;Eby8vdM02xNOcqFlqUwJPLlmEtlCDXJ1OUzFT50uSRZ6IFsuFq2UVErCz4I6tq/K1SZFPTOtr/KBHBeksoGMGw==&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Azblob, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Azdls","type":0,"sectionRef":"#","url":"/docs/services/azdls","content":"","keywords":"","version":"Next"},{"title":"Notes​","type":1,"pageTitle":"Azdls","url":"/docs/services/azdls#notes","content":" azdls is different from azfile service which used to visit Azure File Storage.  ","version":"Next","tagName":"h2"},{"title":"Capabilities​","type":1,"pageTitle":"Azdls","url":"/docs/services/azdls#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Azdls","url":"/docs/services/azdls#configuration","content":" root: Set the work dir for backend.filesystem: Set the filesystem name for backend.endpoint: Set the endpoint for backend.account_name: Set the account_name for backend.account_key: Set the account_key for backend.  Refer to public API docs for more information.  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Azdls","url":"/docs/services/azdls#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Azdls","url":"/docs/services/azdls#via-builder","content":" use std::sync::Arc; use anyhow::Result; use opendal::services::Azdls; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // Create azdls backend builder. let mut builder = Azdls::default(); // Set the root for azdls, all operations will happen under this root. // // NOTE: the root must be absolute path. builder.root(&quot;/path/to/dir&quot;); // Set the filesystem name, this is required. builder.filesystem(&quot;test&quot;); // Set the endpoint, this is required. // // For examples: // - &quot;https://accountname.dfs.core.windows.net&quot; builder.endpoint(&quot;https://accountname.dfs.core.windows.net&quot;); // Set the account_name and account_key. // // OpenDAL will try load credential from the env. // If credential not set and no valid credential in env, OpenDAL will // send request without signing like anonymous user. builder.account_name(&quot;account_name&quot;); builder.account_key(&quot;account_key&quot;); // `Accessor` provides the low level APIs, we will use `Operator` normally. let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Azdls","url":"/docs/services/azdls#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); map.insert(&quot;filesystem&quot;.to_string(), &quot;test&quot;.to_string()); map.insert(&quot;endpoint&quot;.to_string(), &quot;https://accountname.dfs.core.windows.net&quot;.to_string()); map.insert(&quot;account_name&quot;.to_string(), &quot;account_name&quot;.to_string()); map.insert(&quot;account_key&quot;.to_string(), &quot;account_key&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Azdls, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Quickstart","type":0,"sectionRef":"#","url":"/docs/quickstart","content":"","keywords":"","version":"Next"},{"title":"Rust core​","type":1,"pageTitle":"Quickstart","url":"/docs/quickstart#rust-core","content":" OpenDAL's core is implemented in Rust programming language. The most convenient way to use OpenDAL in your Rust program add the OpenDAL Cargo crate as a dependency.  ","version":"Next","tagName":"h2"},{"title":"Install​","type":1,"pageTitle":"Quickstart","url":"/docs/quickstart#install","content":" Run the following Cargo command in your project directory:  cargo add opendal   Or add the following line to your Cargo.toml:  opendal = &quot;0.40.0&quot;   ","version":"Next","tagName":"h3"},{"title":"Demo​","type":1,"pageTitle":"Quickstart","url":"/docs/quickstart#demo","content":" Try it out:  use opendal::Result; use opendal::layers::LoggingLayer; use opendal::services; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // Pick a builder and configure it. let mut builder = services::S3::default(); builder.bucket(&quot;test&quot;); // Init an operator let op = Operator::new(builder)? // Init with logging layer enabled. .layer(LoggingLayer::default()) .finish(); // Write data op.write(&quot;hello.txt&quot;, &quot;Hello, World!&quot;).await?; // Read data let bs = op.read(&quot;hello.txt&quot;).await?; // Fetch metadata let meta = op.stat(&quot;hello.txt&quot;).await?; let mode = meta.mode(); let length = meta.content_length(); // Delete op.delete(&quot;hello.txt&quot;).await?; Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Java binding​","type":1,"pageTitle":"Quickstart","url":"/docs/quickstart#java-binding","content":" OpenDAL's Java binding is released to Maven central as org.apache.opendal:opendal-java:${version}.  ","version":"Next","tagName":"h2"},{"title":"Install​","type":1,"pageTitle":"Quickstart","url":"/docs/quickstart#install-1","content":" Maven​  Generally, you can first add the os-maven-plugin for automatically detect the classifier based on your platform:  &lt;build&gt; &lt;extensions&gt; &lt;extension&gt; &lt;groupId&gt;kr.motd.maven&lt;/groupId&gt; &lt;artifactId&gt;os-maven-plugin&lt;/artifactId&gt; &lt;version&gt;1.7.0&lt;/version&gt; &lt;/extension&gt; &lt;/extensions&gt; &lt;/build&gt;   Then add the dependency to opendal-java as following:  &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.opendal&lt;/groupId&gt; &lt;artifactId&gt;opendal-java&lt;/artifactId&gt; &lt;version&gt;${opendal.version}&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.opendal&lt;/groupId&gt; &lt;artifactId&gt;opendal-java&lt;/artifactId&gt; &lt;version&gt;${opendal.version}&lt;/version&gt; &lt;classifier&gt;${os.detected.classifier}&lt;/classifier&gt; &lt;/dependency&gt; &lt;/dependencies&gt;   Gradle​  For Gradle, you can first add the com.google.osdetector for automatically detect the classifier based on your platform:  plugins { id &quot;com.google.osdetector&quot; version &quot;1.7.3&quot; }   Then add the dependency to opendal-java as following:  dependencies { implementation &quot;org.apache.opendal:opendal-java:$opendal.version&quot; implementation &quot;org.apache.opendal:opendal-java:$opendal.version:$osdetector.classifier&quot; }   Classified library​  For details in specifying classified library, read the dedicated explanation.  ","version":"Next","tagName":"h3"},{"title":"Demo​","type":1,"pageTitle":"Quickstart","url":"/docs/quickstart#demo-1","content":" Try it out:  // Configure service final Map&lt;String, String&gt; conf = new HashMap&lt;&gt;(); conf.put(&quot;root&quot;, &quot;/tmp&quot;); // Construct operator final Operator op = Operator.of(&quot;fs&quot;, conf); // Write data op.write(&quot;hello.txt&quot;, &quot;Hello, World!&quot;).join(); // Read data final byte[] bs = op.read(&quot;hello.txt&quot;).join(); // Delete op.delete(&quot;hello.txt&quot;).join();   ","version":"Next","tagName":"h3"},{"title":"Python binding​","type":1,"pageTitle":"Quickstart","url":"/docs/quickstart#python-binding","content":" OpenDAL's Python binding is released to PyPI repository as opendal.  ","version":"Next","tagName":"h2"},{"title":"Install​","type":1,"pageTitle":"Quickstart","url":"/docs/quickstart#install-2","content":" Run the following command to install opendal:  pip install opendal   ","version":"Next","tagName":"h3"},{"title":"Demo​","type":1,"pageTitle":"Quickstart","url":"/docs/quickstart#demo-2","content":" Try it out:  import opendal import asyncio async def main(): op = opendal.AsyncOperator(&quot;fs&quot;, root=&quot;/tmp&quot;) await op.write(&quot;test.txt&quot;, b&quot;Hello World&quot;) print(await op.read(&quot;test.txt&quot;)) asyncio.run(main())   ","version":"Next","tagName":"h3"},{"title":"Node.js binding​","type":1,"pageTitle":"Quickstart","url":"/docs/quickstart#nodejs-binding","content":" OpenDAL's Python binding is released to npm registry as opendal.  ","version":"Next","tagName":"h2"},{"title":"Install​","type":1,"pageTitle":"Quickstart","url":"/docs/quickstart#install-3","content":" Run the following command to install opendal:  npm install opendal   ","version":"Next","tagName":"h3"},{"title":"Demo​","type":1,"pageTitle":"Quickstart","url":"/docs/quickstart#demo-3","content":" Try it out:  import { Operator } from &quot;opendal&quot;; async function main() { const op = new Operator(&quot;fs&quot;, { root: &quot;/tmp&quot; }); await op.write(&quot;test&quot;, &quot;Hello, World!&quot;); const bs = await op.read(&quot;test&quot;); console.log(new TextDecoder().decode(bs)); const meta = await op.stat(&quot;test&quot;); console.log(`contentLength: ${meta.contentLength}`); }  ","version":"Next","tagName":"h3"},{"title":"Cacache","type":0,"sectionRef":"#","url":"/docs/services/cacache","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Cacache","url":"/docs/services/cacache#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Cacache","url":"/docs/services/cacache#configuration","content":" datadir: Set the path to the cacache data directory  You can refer to [CacacheBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Cacache","url":"/docs/services/cacache#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Cacache","url":"/docs/services/cacache#via-builder","content":" use anyhow::Result; use opendal::services::Cacache; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Cacache::default(); builder.datadir(&quot;/tmp/opendal/cacache&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Cacache","url":"/docs/services/cacache#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::services::Cacache; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;datadir&quot;.to_string(), &quot;/tmp/opendal/cacache&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Cacache, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"COS","type":0,"sectionRef":"#","url":"/docs/services/cos","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"COS","url":"/docs/services/cos#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"COS","url":"/docs/services/cos#configuration","content":" root: Set the work directory for backendbucket: Set the container name for backendendpoint: Customizable endpoint settingaccess_key_id: Set the access_key_id for backend.secret_access_key: Set the secret_access_key for backend.  You can refer to [CosBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"COS","url":"/docs/services/cos#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"COS","url":"/docs/services/cos#via-builder","content":" use anyhow::Result; use opendal::services::Cos; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // create backend builder let mut builder = Cos::default(); // set the storage bucket for OpenDAL builder.bucket(&quot;test&quot;); // set the endpoint for OpenDAL builder.endpoint(&quot;https://cos.ap-singapore.myqcloud.com&quot;); // Set the access_key_id and secret_access_key. // // OpenDAL will try load credential from the env. // If credential not set and no valid credential in env, OpenDAL will // send request without signing like anonymous user. builder.secret_id(&quot;secret_id&quot;); builder.secret_key(&quot;secret_access_key&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"COS","url":"/docs/services/cos#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;bucket&quot;.to_string(), &quot;test&quot;.to_string()); map.insert(&quot;endpoint&quot;.to_string(), &quot;https://cos.ap-singapore.myqcloud.com&quot;.to_string()); map.insert(&quot;secret_id&quot;.to_string(), &quot;secret_id&quot;.to_string()); map.insert(&quot;secret_key&quot;.to_string(), &quot;secret_access_key&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Cos, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"DashMap","type":0,"sectionRef":"#","url":"/docs/services/dashmap","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"DashMap","url":"/docs/services/dashmap#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking ","version":"Next","tagName":"h2"},{"title":"Dropbox","type":0,"sectionRef":"#","url":"/docs/services/dropbox","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Dropbox","url":"/docs/services/dropbox#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list batch blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Dropbox","url":"/docs/services/dropbox#configuration","content":" root: Set the work directory for this backend.  ","version":"Next","tagName":"h2"},{"title":"Credentials related​","type":1,"pageTitle":"Dropbox","url":"/docs/services/dropbox#credentials-related","content":" Just provide Access Token (Temporary)​  access_token: set the access_token for this backend. Please notice its expiration.  Or provide Client ID and Client Secret and refresh token (Long Term)​  If you want to let OpenDAL to refresh the access token automatically, please provide the following fields:  refresh_token: set the refresh_token for dropbox apiclient_id: set the client_id for dropbox apiclient_secret: set the client_secret for dropbox api  OpenDAL is a library, it cannot do the first step of OAuth2 for you. You need to get authorization code from user by calling Dropbox's authorize url and exchange it for refresh token.  Please refer to Dropbox OAuth2 Guidefor more information.  You can refer to [DropboxBuilder]'s docs for more information  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Dropbox","url":"/docs/services/dropbox#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Dropbox","url":"/docs/services/dropbox#via-builder","content":" use anyhow::Result; use opendal::raw::OpWrite; use opendal::services::Dropbox; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Dropbox::default(); builder.root(&quot;/opendal&quot;); builder.access_token(&quot;&lt;token&gt;&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Dropbox","url":"/docs/services/dropbox#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); map.insert(&quot;access_token&quot;.to_string(), &quot;your_access_token&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Dropbox, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Etcd","type":0,"sectionRef":"#","url":"/docs/services/etcd","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Etcd","url":"/docs/services/etcd#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Etcd","url":"/docs/services/etcd#configuration","content":" root: Set the working directory of OpenDALendpoints: Set the network address of etcd serversusername: Set the username of Etcdpassword: Set the password for authenticationca_path: Set the ca path to the etcd connectioncert_path: Set the cert path to the etcd connectionkey_path: Set the key path to the etcd connection  You can refer to [EtcdBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Etcd","url":"/docs/services/etcd#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Etcd","url":"/docs/services/etcd#via-builder","content":" use anyhow::Result; use opendal::services::Etcd; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Etcd::default(); // this will build a Operator accessing etcd which runs on http://127.0.0.1:2379 let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Etcd","url":"/docs/services/etcd#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); map.insert(&quot;endpoints&quot;.to_string(), &quot;http://127.0.0.1:2379&quot;.to_string()); map.insert(&quot;username&quot;.to_string(), &quot;your_username&quot;.to_string()); map.insert(&quot;password&quot;.to_string(), &quot;your_password&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Etcd, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"FoundationDB","type":0,"sectionRef":"#","url":"/docs/services/foundationdb","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"FoundationDB","url":"/docs/services/foundationdb#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  Note: As for Known Limitations - FoundationDB, keys cannot exceed 10,000 bytes in size, and values cannot exceed 100,000 bytes in size. Errors will be raised by OpenDAL if these limits are exceeded.  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"FoundationDB","url":"/docs/services/foundationdb#configuration","content":" root: Set the work directory for this backend.config_path: Set the configuration path for foundationdb. If not provided, the default configuration path will be used.  You can refer to [FoundationdbBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"FoundationDB","url":"/docs/services/foundationdb#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"FoundationDB","url":"/docs/services/foundationdb#via-builder","content":" use anyhow::Result; use opendal::services::Foundationdb; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Foundationdb::default(); builder.config_path(&quot;/etc/foundationdb/foundationdb.conf&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"FoundationDB","url":"/docs/services/foundationdb#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); map.insert(&quot;config_path&quot;.to_string(), &quot;/path/to/config&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Foundationdb, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"D1","type":0,"sectionRef":"#","url":"/docs/services/d1","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"D1","url":"/docs/services/d1#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"D1","url":"/docs/services/d1#configuration","content":" root: Set the working directory of OpenDALtoken: Set the token of cloudflare apiaccount_id: Set the account id of cloudflare apidatabase_id: Set the database id of cloudflare apitable: Set the table of D1 Databasekey_field: Set the key field of D1 Databasevalue_field: Set the value field of D1 Database  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"D1","url":"/docs/services/d1#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"D1","url":"/docs/services/d1#via-builder","content":" use anyhow::Result; use opendal::services::D1; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = D1::default(); builder .token(&quot;token&quot;) .account_id(&quot;account_id&quot;) .database_id(&quot;database_id&quot;) .table(&quot;table&quot;) .key_field(&quot;key_field&quot;) .value_field(&quot;value_field&quot;); let op = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"D1","url":"/docs/services/d1#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;token&quot;.to_string(), &quot;token&quot;.to_string()); map.insert(&quot;account_id&quot;.to_string(), &quot;account_id&quot;.to_string()); map.insert(&quot;database_id&quot;.to_string(), &quot;database_id&quot;.to_string()); map.insert(&quot;table&quot;.to_string(), &quot;table&quot;.to_string()); map.insert(&quot;key_field&quot;.to_string(), &quot;key_field&quot;.to_string()); map.insert(&quot;value_field&quot;.to_string(), &quot;value_field&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::D1, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"FTP","type":0,"sectionRef":"#","url":"/docs/services/ftp","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"FTP","url":"/docs/services/ftp#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"FTP","url":"/docs/services/ftp#configuration","content":" endpoint: Set the endpoint for connectionroot: Set the work directory for backenduser: Set the login userpassword: Set the login password  You can refer to [FtpBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"FTP","url":"/docs/services/ftp#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"FTP","url":"/docs/services/ftp#via-builder","content":" use anyhow::Result; use opendal::services::Ftp; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Ftp::default(); builder.endpoint(&quot;127.0.0.1&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"FTP","url":"/docs/services/ftp#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;endpoint&quot;.to_string(), &quot;127.0.0.1&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Ftp, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Fs","type":0,"sectionRef":"#","url":"/docs/services/fs","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Fs","url":"/docs/services/fs#capabilities","content":" This service can be used to:   stat read write append create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Fs","url":"/docs/services/fs#configuration","content":" root: Set the work dir for backend.  You can refer to [FsBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Fs","url":"/docs/services/fs#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Fs","url":"/docs/services/fs#via-builder","content":" use std::sync::Arc; use anyhow::Result; use opendal::services::Fs; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // Create fs backend builder. let mut builder = Fs::default(); // Set the root for fs, all operations will happen under this root. // // NOTE: the root must be absolute path. builder.root(&quot;/tmp&quot;); // `Accessor` provides the low level APIs, we will use `Operator` normally. let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Fs","url":"/docs/services/fs#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Fs, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Gcs","type":0,"sectionRef":"#","url":"/docs/services/gcs","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Gcs","url":"/docs/services/gcs#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Gcs","url":"/docs/services/gcs#configuration","content":" root: Set the work directory for backendbucket: Set the container name for backendendpoint: Customizable endpoint settingcredential: Credentials string for GCS service OAuth2 authenticationcredential_path: Local path to credentials file for GCS service OAuth2 authenticationpredefined_acl: Predefined ACL for GCSdefault_storage_class: Default storage class for GCS  Refer to public API docs for more information.  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Gcs","url":"/docs/services/gcs#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Gcs","url":"/docs/services/gcs#via-builder","content":" use anyhow::Result; use opendal::services::Gcs; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // create backend builder let mut builder = Gcs::default(); // set the storage bucket for OpenDAL builder.bucket(&quot;test&quot;); // set the working directory root for GCS // all operations will happen within it builder.root(&quot;/path/to/dir&quot;); // set the credentials string of service account builder.credential(&quot;service account credential&quot;); // set the predefined ACL for GCS builder.predefined_acl(&quot;publicRead&quot;); // set the default storage class for GCS builder.default_storage_class(&quot;STANDARD&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Gcs","url":"/docs/services/gcs#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;bucket&quot;.to_string(), &quot;test&quot;.to_string()); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); map.insert(&quot;credential&quot;.to_string(), &quot;authentication token&quot;.to_string()); map.insert(&quot;predefined_acl&quot;.to_string(), &quot;publicRead&quot;.to_string()); map.insert(&quot;default_storage_class&quot;.to_string(), &quot;STANDARD&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Gcs, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"GHAC","type":0,"sectionRef":"#","url":"/docs/services/ghac","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"GHAC","url":"/docs/services/ghac#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Notes​","type":1,"pageTitle":"GHAC","url":"/docs/services/ghac#notes","content":" This service is mainly provided by GitHub actions.  Refer to Caching dependencies to speed up workflows for more information.  To make this service work as expected, please make sure to either call endpoint and token to configure the URL and credentials, or that the following environment has been setup correctly:  ACTIONS_CACHE_URLACTIONS_RUNTIME_TOKEN  They can be exposed by following action:  - name: Configure Cache Env uses: actions/github-script@v6 with: script: | core.exportVariable('ACTIONS_CACHE_URL', process.env.ACTIONS_CACHE_URL || ''); core.exportVariable('ACTIONS_RUNTIME_TOKEN', process.env.ACTIONS_RUNTIME_TOKEN || '');   To make delete work as expected, GITHUB_TOKEN should also be set via:  env: GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}   ","version":"Next","tagName":"h2"},{"title":"Limitations​","type":1,"pageTitle":"GHAC","url":"/docs/services/ghac#limitations","content":" Unlike other services, ghac doesn't support create empty files. We provide a enable_create_simulation() to support this operation but may result unexpected side effects.  Also, ghac is a cache service which means the data store inside could be automatically evicted at any time.  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"GHAC","url":"/docs/services/ghac#configuration","content":" root: Set the work dir for backend.  Refer to [GhacBuilder]'s public API docs for more information.  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"GHAC","url":"/docs/services/ghac#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"GHAC","url":"/docs/services/ghac#via-builder","content":" use std::sync::Arc; use anyhow::Result; use opendal::services::Ghac; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // Create ghac backend builder. let mut builder = Ghac::default(); // Set the root for ghac, all operations will happen under this root. // // NOTE: the root must be absolute path. builder.root(&quot;/path/to/dir&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"GHAC","url":"/docs/services/ghac#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::services::Ghac; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Ghac, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Gridfs","type":0,"sectionRef":"#","url":"/docs/services/gridfs","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Gridfs","url":"/docs/services/gridfs#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Gridfs","url":"/docs/services/gridfs#configuration","content":" root: Set the working directory of OpenDALconnection_string: Set the connection string of mongodb serverdatabase: Set the database of mongodbbucket: Set the bucket of mongodb gridfschunk_size: Set the chunk size of mongodb gridfs  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Gridfs","url":"/docs/services/gridfs#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Gridfs","url":"/docs/services/gridfs#via-builder","content":" use anyhow::Result; use opendal::services::Gridfs; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Gridfs::default(); builder.root(&quot;/&quot;); builder.connection_string(&quot;mongodb://myUser:myPassword@localhost:27017/myAuthDB&quot;); builder.database(&quot;your_database&quot;); builder.bucket(&quot;your_bucket&quot;); // The chunk size in bytes used to break the user file into chunks. builder.chunk_size(255); let op = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Gridfs","url":"/docs/services/gridfs#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;connection_string&quot;.to_string(), &quot;connection_string&quot;.to_string()); map.insert(&quot;database&quot;.to_string(), &quot;database&quot;.to_string()); map.insert(&quot;bucket&quot;.to_string(), &quot;bucket&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Gridfs, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Gdrive","type":0,"sectionRef":"#","url":"/docs/services/gdrive","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Gdrive","url":"/docs/services/gdrive#capabilities","content":" This service can be used to:   stat read write delete create_dir list copy rename batch  Configuration  root: Set the work directory for backend  ","version":"Next","tagName":"h2"},{"title":"Credentials related​","type":1,"pageTitle":"Gdrive","url":"/docs/services/gdrive#credentials-related","content":" Just provide Access Token (Temporary)​  access_token: set the access_token for google drive api Please notice its expiration.  Or provide Client ID and Client Secret and refresh token (Long Term)​  If you want to let OpenDAL to refresh the access token automatically, please provide the following fields:  refresh_token: set the refresh_token for google drive apiclient_id: set the client_id for google drive apiclient_secret: set the client_secret for google drive api  OpenDAL is a library, it cannot do the first step of OAuth2 for you. You need to get authorization code from user by calling GoogleDrive's authorize url and exchange it for refresh token.  Make sure you have enabled Google Drive API in your Google Cloud Console. And your OAuth scope contains https://www.googleapis.com/auth/drive.  Please refer to GoogleDrive OAuth2 Flowfor more information.  You can refer to [GdriveBuilder]'s docs for more information  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Gdrive","url":"/docs/services/gdrive#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Gdrive","url":"/docs/services/gdrive#via-builder","content":" use anyhow::Result; use opendal::services::Gdrive; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Gdrive::default(); builder.root(&quot;/test&quot;); builder.access_token(&quot;&lt;token&gt;&quot;); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Gdrive","url":"/docs/services/gdrive#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); map.insert(&quot;access_token&quot;.to_string(), &quot;your_access_token&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Gdrive, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"HDFS","type":0,"sectionRef":"#","url":"/docs/services/hdfs","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"HDFS","url":"/docs/services/hdfs#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking append  ","version":"Next","tagName":"h2"},{"title":"Differences with webhdfs​","type":1,"pageTitle":"HDFS","url":"/docs/services/hdfs#differences-with-webhdfs","content":" [Webhdfs][crate::services::Webhdfs] is powered by hdfs's RESTful HTTP API.  ","version":"Next","tagName":"h2"},{"title":"Features​","type":1,"pageTitle":"HDFS","url":"/docs/services/hdfs#features","content":" HDFS support needs to enable feature services-hdfs.  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"HDFS","url":"/docs/services/hdfs#configuration","content":" root: Set the work dir for backend.name_node: Set the name node for backend.kerberos_ticket_cache_path: Set the kerberos ticket cache path for backend, this should be gotten by klist after kinituser: Set the user for backendenable_append: enable the append capacity. Default is false.  Refer to [HdfsBuilder]'s public API docs for more information.  ","version":"Next","tagName":"h2"},{"title":"Environment​","type":1,"pageTitle":"HDFS","url":"/docs/services/hdfs#environment","content":" HDFS needs some environment set correctly.  JAVA_HOME: the path to java home, could be found via java -XshowSettings:properties -versionHADOOP_HOME: the path to hadoop home, opendal relays on this env to discover hadoop jars and set CLASSPATH automatically.  Most of the time, setting JAVA_HOME and HADOOP_HOME is enough. But there are some edge cases:  If meeting errors like the following:  error while loading shared libraries: libjvm.so: cannot open shared object file: No such file or directory   Java's lib are not including in pkg-config find path, please set LD_LIBRARY_PATH:  export LD_LIBRARY_PATH=${JAVA_HOME}/lib/server:${LD_LIBRARY_PATH}   The path of libjvm.so could be different, please keep an eye on it.  If meeting errors like the following:  (unable to get stack trace for java.lang.NoClassDefFoundError exception: ExceptionUtils::getStackTrace error.)   CLASSPATH is not set correctly or your hadoop installation is incorrect.  To set CLASSPATH:  export CLASSPATH=$(find $HADOOP_HOME -iname &quot;*.jar&quot; | xargs echo | tr ' ' ':'):${CLASSPATH}   If HDFS has High Availability (HA) enabled with multiple available NameNodes, some configuration is required:  Obtain the entire HDFS config folder (usually located at HADOOP_HOME/etc/hadoop).Set the environment variable HADOOP_CONF_DIR to the path of this folder.  export HADOOP_CONF_DIR=&lt;path of the config folder&gt;   Append the HADOOP_CONF_DIR to the CLASSPATH  export CLASSPATH=$HADOOP_CONF_DIR:$HADOOP_CLASSPATH:$CLASSPATH   Use the cluster_name specified in the core-site.xml file (located in the HADOOP_CONF_DIR folder) to replace namenode:port.  builder.name_node(&quot;hdfs://cluster_name&quot;);   ","version":"Next","tagName":"h2"},{"title":"macOS Specific Note​","type":1,"pageTitle":"HDFS","url":"/docs/services/hdfs#macos-specific-note","content":" If you encounter an issue during the build process on macOS with an error message similar to:  ld: unknown file type in $HADOOP_HOME/lib/native/libhdfs.so.0.0.0 clang: error: linker command failed with exit code 1 (use -v to see invocation)   This error is likely due to the fact that the official Hadoop build includes the libhdfs.so file for the x86-64 architecture, which is not compatible with aarch64 architecture required for MacOS.  To resolve this issue, you can add hdrs as a dependency in your Rust application's Cargo.toml file, and enable the vendored feature:  [dependencies] hdrs = { version = &quot;&lt;version_number&gt;&quot;, features = [&quot;vendored&quot;] }   Enabling the vendored feature ensures that hdrs includes the necessary libhdfs.so library built for the correct architecture.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"HDFS","url":"/docs/services/hdfs#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"HDFS","url":"/docs/services/hdfs#via-builder","content":" use std::sync::Arc; use anyhow::Result; use opendal::services::Hdfs; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // Create fs backend builder. let mut builder = Hdfs::default(); // Set the name node for hdfs. // If the string starts with a protocol type such as file://, hdfs://, or gs://, this protocol type will be used. builder.name_node(&quot;hdfs://127.0.0.1:9000&quot;); // Set the root for hdfs, all operations will happen under this root. // // NOTE: the root must be absolute path. builder.root(&quot;/tmp&quot;); // Enable the append capacity for hdfs. // // Note: HDFS run in non-distributed mode doesn't support append. builder.enable_append(true); // `Accessor` provides the low level APIs, we will use `Operator` normally. let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"HDFS","url":"/docs/services/hdfs#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;name_node&quot;.to_string(), &quot;hdfs://127.0.0.1:9000&quot;.to_string()); map.insert(&quot;root&quot;.to_string(), &quot;/tmp&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Hdfs, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"HTTP","type":0,"sectionRef":"#","url":"/docs/services/http","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"HTTP","url":"/docs/services/http#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Notes​","type":1,"pageTitle":"HTTP","url":"/docs/services/http#notes","content":" Only read and stat are supported. We can use this service to visit any HTTP Server like nginx, caddy.  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"HTTP","url":"/docs/services/http#configuration","content":" endpoint: set the endpoint for httproot: Set the work directory for backend  You can refer to [HttpBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"HTTP","url":"/docs/services/http#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"HTTP","url":"/docs/services/http#via-builder","content":" use anyhow::Result; use opendal::services::Http; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // create http backend builder let mut builder = Http::default(); builder.endpoint(&quot;127.0.0.1&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"HTTP","url":"/docs/services/http#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;endpoint&quot;.to_string(), &quot;127.0.0.1&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Http, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"IPFS","type":0,"sectionRef":"#","url":"/docs/services/ipfs","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"IPFS","url":"/docs/services/ipfs#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"IPFS","url":"/docs/services/ipfs#configuration","content":" root: Set the work directory for backendendpoint: Customizable endpoint setting  You can refer to [IpfsBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"IPFS","url":"/docs/services/ipfs#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"IPFS","url":"/docs/services/ipfs#via-builder","content":" use anyhow::Result; use opendal::services::Ipfs; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // create backend builder let mut builder = Ipfs::default(); // set the endpoint for OpenDAL builder.endpoint(&quot;https://ipfs.io&quot;); // set the root for OpenDAL builder.root(&quot;/ipfs/QmPpCt1aYGb9JWJRmXRUnmJtVgeFFTJGzWFYEEX7bo9zGJ&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"IPFS","url":"/docs/services/ipfs#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;endpoint&quot;.to_string(), &quot;https://ipfs.io&quot;.to_string()); map.insert(&quot;root&quot;.to_string(), &quot;/ipfs/QmPpCt1aYGb9JWJRmXRUnmJtVgeFFTJGzWFYEEX7bo9zGJ&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Ipfs, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"IPMFS","type":0,"sectionRef":"#","url":"/docs/services/ipmfs","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"IPMFS","url":"/docs/services/ipmfs#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking ","version":"Next","tagName":"h2"},{"title":"Hugging Face","type":0,"sectionRef":"#","url":"/docs/services/huggingface","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Hugging Face","url":"/docs/services/huggingface#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configurations​","type":1,"pageTitle":"Hugging Face","url":"/docs/services/huggingface#configurations","content":" repo_type: The type of the repository.repo_id: The id of the repository.revision: The revision of the repository.root: Set the work directory for backend.token: The token for accessing the repository.  Refer to [HuggingfaceBuilder]'s public API docs for more information.  ","version":"Next","tagName":"h2"},{"title":"Examples​","type":1,"pageTitle":"Hugging Face","url":"/docs/services/huggingface#examples","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Hugging Face","url":"/docs/services/huggingface#via-builder","content":" use std::sync::Arc; use anyhow::Result; use opendal::services::Huggingface; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // Create Huggingface backend builder let mut builder = Huggingface::default(); // set the type of Huggingface repository builder.repo_type(&quot;dataset&quot;); // set the id of Huggingface repository builder.repo_id(&quot;databricks/databricks-dolly-15k&quot;); // set the revision of Huggingface repository builder.revision(&quot;main&quot;); // set the root for Huggingface, all operations will happen under this root builder.root(&quot;/path/to/dir&quot;); // set the token for accessing the repository builder.token(&quot;access_token&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Hugging Face","url":"/docs/services/huggingface#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;repo_type&quot;.to_string(), &quot;dataset&quot;.to_string()); map.insert(&quot;repo_id&quot;.to_string(), &quot;databricks/databricks-dolly-15k&quot;.to_string()); map.insert(&quot;revision&quot;.to_string(), &quot;main&quot;.to_string()); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); map.insert(&quot;token&quot;.to_string(), &quot;access_token&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Huggingface, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Memcached","type":0,"sectionRef":"#","url":"/docs/services/memcached","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Memcached","url":"/docs/services/memcached#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Memcached","url":"/docs/services/memcached#configuration","content":" root: Set the working directory of OpenDALusername: Set the username for authentication.password: Set the password for authentication.endpoint: Set the network address of memcached serverdefault_ttl: Set the ttl for memcached service.  You can refer to [MemcachedBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Memcached","url":"/docs/services/memcached#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Memcached","url":"/docs/services/memcached#via-builder","content":" use anyhow::Result; use opendal::services::Memcached; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // create memcached backend builder let mut builder = Memcached::default(); builder.endpoint(&quot;tcp://127.0.0.1:11211&quot;); // if you enable authentication, set username and password for authentication // builder.username(&quot;admin&quot;); // builder.password(&quot;password&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Memcached","url":"/docs/services/memcached#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;endpoint&quot;.to_string(), &quot;tcp://127.0.0.1:11211&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Memcached, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"LibSQL","type":0,"sectionRef":"#","url":"/docs/services/libsql","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"LibSQL","url":"/docs/services/libsql#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"LibSQL","url":"/docs/services/libsql#configuration","content":" root: Set the working directory of OpenDALconnection_string: Set the connection string for libsql serverauth_token: Set the authentication token for libsql servertable: Set the table of libsqlkey_field: Set the key field of libsqlvalue_field: Set the value field of libsql  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"LibSQL","url":"/docs/services/libsql#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"LibSQL","url":"/docs/services/libsql#via-builder","content":" use anyhow::Result; use opendal::services::Libsql; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Libsql::default(); builder.root(&quot;/&quot;); builder.connection_string(&quot;https://example.com/db&quot;); builder.auth_token(&quot;secret&quot;); builder.table(&quot;your_table&quot;); // key field type in the table should be compatible with Rust's &amp;str like text builder.key_field(&quot;key&quot;); // value field type in the table should be compatible with Rust's Vec&lt;u8&gt; like bytea builder.value_field(&quot;value&quot;); let op = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"LibSQL","url":"/docs/services/libsql#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/&quot;.to_string()); map.insert(&quot;connection_string&quot;.to_string(), &quot;https://example.com/db&quot;.to_string()); map.insert(&quot;auth_token&quot;.to_string(), &quot;secret&quot;.to_string()); map.insert(&quot;table&quot;.to_string(), &quot;your_table&quot;.to_string()); map.insert(&quot;key_field&quot;.to_string(), &quot;key&quot;.to_string()); map.insert(&quot;value_field&quot;.to_string(), &quot;value&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Libsql, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Moka","type":0,"sectionRef":"#","url":"/docs/services/moka","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Moka","url":"/docs/services/moka#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Moka","url":"/docs/services/moka#configuration","content":" name: Set the name for this cache instance.max_capacity: Set the max capacity of the cache.time_to_live: Set the time to live of the cache.time_to_idle: Set the time to idle of the cache.num_segments: Set the segments number of the cache.  You can refer to [MokaBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Moka","url":"/docs/services/moka#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Moka","url":"/docs/services/moka#via-builder","content":" use anyhow::Result; use opendal::services::Moka; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Moka::default(); builder.name(&quot;opendal&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Moka","url":"/docs/services/moka#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;name&quot;.to_string(), &quot;your_cache_name&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Moka, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Memory","type":0,"sectionRef":"#","url":"/docs/services/memory","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Memory","url":"/docs/services/memory#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Memory","url":"/docs/services/memory#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Memory","url":"/docs/services/memory#via-builder","content":" use std::sync::Arc; use anyhow::Result; use opendal::services::Memory; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Memory::default(); builder.root(&quot;/tmp&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Memory","url":"/docs/services/memory#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Memory, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"MongoDB","type":0,"sectionRef":"#","url":"/docs/services/mongodb","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"MongoDB","url":"/docs/services/mongodb#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"MongoDB","url":"/docs/services/mongodb#configuration","content":" root: Set the working directory of OpenDALconnection_string: Set the connection string of mongodb serverdatabase: Set the database of mongodbcollection: Set the collection of mongodbkey_field: Set the key field of mongodbvalue_field: Set the value field of mongodb  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"MongoDB","url":"/docs/services/mongodb#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"MongoDB","url":"/docs/services/mongodb#via-builder","content":" use anyhow::Result; use opendal::services::Mongodb; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Mongodb::default(); builder.root(&quot;/&quot;); builder.connection_string(&quot;mongodb://myUser:myPassword@localhost:27017/myAuthDB&quot;); builder.database(&quot;your_database&quot;); builder.collection(&quot;your_collection&quot;); // key field type in the table should be compatible with Rust's &amp;str like text builder.key_field(&quot;key&quot;); // value field type in the table should be compatible with Rust's Vec&lt;u8&gt; like bytea builder.value_field(&quot;value&quot;); let op = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"MongoDB","url":"/docs/services/mongodb#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/&quot;.to_string()); map.insert(&quot;connection_string&quot;.to_string(), &quot;mongodb://myUser:myPassword@localhost:27017/myAuthDB&quot;.to_string()); map.insert(&quot;database&quot;.to_string(), &quot;your_database&quot;.to_string()); map.insert(&quot;collection&quot;.to_string(), &quot;your_collection&quot;.to_string()); map.insert(&quot;key_field&quot;.to_string(), &quot;key&quot;.to_string()); map.insert(&quot;value_field&quot;.to_string(), &quot;value&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Mongodb, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"OneDrive","type":0,"sectionRef":"#","url":"/docs/services/onedrive","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"OneDrive","url":"/docs/services/onedrive#capabilities","content":" This service can be used to:   read write list copy rename scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Notes​","type":1,"pageTitle":"OneDrive","url":"/docs/services/onedrive#notes","content":" Currently, only OneDrive Personal is supported.  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"OneDrive","url":"/docs/services/onedrive#configuration","content":" access_token: set the access_token for Graph APIroot: Set the work directory for backend  You can refer to [OnedriveBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"OneDrive","url":"/docs/services/onedrive#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"OneDrive","url":"/docs/services/onedrive#via-builder","content":" use anyhow::Result; use opendal::services::Onedrive; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // create backend builder let mut builder = Onedrive::default(); builder.access_token(&quot;xxx&quot;).root(&quot;/path/to/root&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"OneDrive","url":"/docs/services/onedrive#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); map.insert(&quot;access_token&quot;.to_string(), &quot;your_access_token&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Onedrive, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"MySQL","type":0,"sectionRef":"#","url":"/docs/services/mysql","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"MySQL","url":"/docs/services/mysql#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"MySQL","url":"/docs/services/mysql#configuration","content":" root: Set the working directory of OpenDALconnection_string: Set the connection string of mysql servertable: Set the table of mysqlkey_field: Set the key field of mysqlvalue_field: Set the value field of mysql  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"MySQL","url":"/docs/services/mysql#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"MySQL","url":"/docs/services/mysql#via-builder","content":" use anyhow::Result; use opendal::services::Mysql; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Mysql::default(); builder.root(&quot;/&quot;); builder.connection_string(&quot;mysql://you_username:your_password@127.0.0.1:5432/your_database&quot;); builder.table(&quot;your_table&quot;); // key field type in the table should be compatible with Rust's &amp;str like text builder.key_field(&quot;key&quot;); // value field type in the table should be compatible with Rust's Vec&lt;u8&gt; like bytea builder.value_field(&quot;value&quot;); let op = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"MySQL","url":"/docs/services/mysql#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::services::Mysql; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;connection_string&quot;.to_string(), &quot;mysql://you_username:your_password@127.0.0.1:5432/your_database&quot;.to_string()); map.insert(&quot;table&quot;.to_string(), &quot;your_table&quot;.to_string()); map.insert(&quot;key_field&quot;.to_string(), &quot;your_key_field&quot;.to_string()); map.insert(&quot;value_field&quot;.to_string(), &quot;your_value_field&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Mysql, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Obs","type":0,"sectionRef":"#","url":"/docs/services/obs","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Obs","url":"/docs/services/obs#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Obs","url":"/docs/services/obs#configuration","content":" root: Set the work directory for backendbucket: Set the container name for backendendpoint: Customizable endpoint settingaccess_key_id: Set the access_key_id for backend.secret_access_key: Set the secret_access_key for backend.  You can refer to [ObsBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Obs","url":"/docs/services/obs#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Obs","url":"/docs/services/obs#via-builder","content":" use anyhow::Result; use opendal::services::Obs; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // create backend builder let mut builder = Obs::default(); // set the storage bucket for OpenDAL builder.bucket(&quot;test&quot;); builder.endpoint(&quot;obs.cn-north-1.myhuaweicloud.com&quot;); // Set the access_key_id and secret_access_key. // // OpenDAL will try load credential from the env. // If credential not set and no valid credential in env, OpenDAL will // send request without signing like anonymous user. builder.access_key_id(&quot;access_key_id&quot;); builder.secret_access_key(&quot;secret_access_key&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Obs","url":"/docs/services/obs#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;bucket&quot;.to_string(), &quot;test&quot;.to_string()); map.insert(&quot;endpoint&quot;.to_string(), &quot;obs.cn-north-1.myhuaweicloud.com&quot;.to_string()); map.insert(&quot;access_key_id&quot;.to_string(), &quot;access_key_id&quot;.to_string()); map.insert(&quot;secret_access_key&quot;.to_string(), &quot;secret_access_key&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Obs, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"PostgreSQL","type":0,"sectionRef":"#","url":"/docs/services/postgresql","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"PostgreSQL","url":"/docs/services/postgresql#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"PostgreSQL","url":"/docs/services/postgresql#configuration","content":" root: Set the working directory of OpenDALconnection_string: Set the connection string of postgres servertable: Set the table of postgresqlkey_field: Set the key field of postgresqlvalue_field: Set the value field of postgresql  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"PostgreSQL","url":"/docs/services/postgresql#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"PostgreSQL","url":"/docs/services/postgresql#via-builder","content":" use anyhow::Result; use opendal::services::Postgresql; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Postgresql::default(); builder.root(&quot;/&quot;); builder.connection_string(&quot;postgresql://you_username:your_password@127.0.0.1:5432/your_database&quot;); builder.table(&quot;your_table&quot;); // key field type in the table should be compatible with Rust's &amp;str like text builder.key_field(&quot;key&quot;); // value field type in the table should be compatible with Rust's Vec&lt;u8&gt; like bytea builder.value_field(&quot;value&quot;); let op = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"PostgreSQL","url":"/docs/services/postgresql#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::services::Postgresql; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;connection_string&quot;.to_string(), &quot;postgresql://you_username:your_password@127.0.0.1:5432/your_database&quot;.to_string()); map.insert(&quot;table&quot;.to_string(), &quot;your_table&quot;.to_string()); map.insert(&quot;key_field&quot;.to_string(), &quot;your_key_field&quot;.to_string()); map.insert(&quot;value_field&quot;.to_string(), &quot;your_value_field&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Postgresql, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Redb","type":0,"sectionRef":"#","url":"/docs/services/redb","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Redb","url":"/docs/services/redb#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Redb","url":"/docs/services/redb#configuration","content":" datadir: Set the path to the redb data directory  You can refer to [RedbBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Redb","url":"/docs/services/redb#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Redb","url":"/docs/services/redb#via-builder","content":" use anyhow::Result; use opendal::services::Redb; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Redb::default(); builder.datadir(&quot;/tmp/opendal/redb&quot;); builder.table(&quot;opendal-redb&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Redb","url":"/docs/services/redb#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut config = HashMap::new(); config.insert(&quot;datadir&quot;.to_string(), &quot;/tmp/opendal/redb&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Redb, config)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Persy","type":0,"sectionRef":"#","url":"/docs/services/persy","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Persy","url":"/docs/services/persy#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Persy","url":"/docs/services/persy#configuration","content":" datafile: Set the path to the persy data file. The directory in the path must already exist.segment: Set the name of the persy segment.index: Set the name of the persy index.  You can refer to [PersyBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Persy","url":"/docs/services/persy#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Persy","url":"/docs/services/persy#via-builder","content":" use anyhow::Result; use opendal::services::Persy; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Persy::default(); builder.datafile(&quot;./test.persy&quot;); builder.segment(&quot;data&quot;); builder.index(&quot;index&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Persy","url":"/docs/services/persy#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut config = HashMap::new(); config.insert(&quot;datafile&quot;.to_string(), &quot;./test.persy&quot;.to_string()); config.insert(&quot;segment&quot;.to_string(), &quot;data&quot;.to_string()); config.insert(&quot;index&quot;.to_string(), &quot;index&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Persy, config)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"OSS","type":0,"sectionRef":"#","url":"/docs/services/oss","content":"","keywords":"","version":"Next"},{"title":"Via Builder​","type":1,"pageTitle":"OSS","url":"/docs/services/oss#via-builder","content":" use std::sync::Arc; use anyhow::Result; use opendal::services::Oss; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // Create OSS backend builder. let mut builder = Oss::default(); // Set the root for oss, all operations will happen under this root. // // NOTE: the root must be absolute path. builder.root(&quot;/path/to/dir&quot;); // Set the bucket name, this is required. builder.bucket(&quot;test&quot;); // Set the endpoint. // // For example: // - &quot;https://oss-ap-northeast-1.aliyuncs.com&quot; // - &quot;https://oss-hangzhou.aliyuncs.com&quot; builder.endpoint(&quot;https://oss-cn-beijing.aliyuncs.com&quot;); // Set the access_key_id and access_key_secret. // // OpenDAL will try load credential from the env. // If credential not set and no valid credential in env, OpenDAL will // send request without signing like anonymous user. builder.access_key_id(&quot;access_key_id&quot;); builder.access_key_secret(&quot;access_key_secret&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h2"},{"title":"Via Config​","type":1,"pageTitle":"OSS","url":"/docs/services/oss#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); map.insert(&quot;bucket&quot;.to_string(), &quot;test&quot;.to_string()); map.insert(&quot;endpoint&quot;.to_string(), &quot;https://oss-cn-beijing.aliyuncs.com&quot;.to_string()); map.insert(&quot;access_key_id&quot;.to_string(), &quot;access_key_id&quot;.to_string()); map.insert(&quot;access_key_secret&quot;.to_string(), &quot;access_key_secret&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Oss, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"SFTP","type":0,"sectionRef":"#","url":"/docs/services/sftp","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"SFTP","url":"/docs/services/sftp#capabilities","content":" This service can be used to:   stat read write append create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"SFTP","url":"/docs/services/sftp#configuration","content":" endpoint: Set the endpoint for connection. The format is same as openssh, using either [user@]hostname or ssh://[user@]hostname[:port]. A username or port that is specified in the endpoint overrides the one set in the builder (but does not change the builder).root: Set the work directory for backend. It uses the default directory set by the remote sftp-server as defaultuser: Set the login userkey: Set the public key for loginknown_hosts_strategy: Set the strategy for known hosts, default to Strictenable_copy: Set whether the remote server has copy-file extension  For security reasons, it doesn't support password login, you can use public key or ssh-copy-id instead.  You can refer to [SftpBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"SFTP","url":"/docs/services/sftp#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"SFTP","url":"/docs/services/sftp#via-builder","content":" use anyhow::Result; use opendal::services::Sftp; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Sftp::default(); builder.endpoint(&quot;127.0.0.1&quot;).user(&quot;test&quot;).key(&quot;test_key&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"SFTP","url":"/docs/services/sftp#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;endpoint&quot;.to_string(), &quot;127.0.0.1&quot;.to_string()); map.insert(&quot;user&quot;.to_string(), &quot;test&quot;.to_string()); map.insert(&quot;key&quot;.to_string(), &quot;test_key&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Sftp, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"RocksDB","type":0,"sectionRef":"#","url":"/docs/services/rocksdb","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"RocksDB","url":"/docs/services/rocksdb#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Note​","type":1,"pageTitle":"RocksDB","url":"/docs/services/rocksdb#note","content":" OpenDAL will build rocksdb from source by default.  To link with existing rocksdb lib, please set one of the following:  ROCKSDB_LIB_DIR to the dir that contains librocksdb.soROCKSDB_STATIC to the dir that contains librocksdb.a  If the version of RocksDB is below 6.0, you may encounter compatibility issues. It is advisable to follow the steps provided in the INSTALLfile to build rocksdb, rather than relying on system libraries that may be outdated and incompatible.  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"RocksDB","url":"/docs/services/rocksdb#configuration","content":" root: Set the working directory of OpenDALdatadir: Set the path to the rocksdb data directory  You can refer to [RocksdbBuilder]'s docs for more information.  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"RocksDB","url":"/docs/services/rocksdb#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"RocksDB","url":"/docs/services/rocksdb#via-builder","content":" use anyhow::Result; use opendal::services::Rocksdb; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Rocksdb::default(); builder.datadir(&quot;/tmp/opendal/rocksdb&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"RocksDB","url":"/docs/services/rocksdb#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;datadir&quot;.to_string(), &quot;/tmp/opendal/rocksdb&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Rocksdb, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Redis","type":0,"sectionRef":"#","url":"/docs/services/redis","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Redis","url":"/docs/services/redis#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Redis","url":"/docs/services/redis#configuration","content":" root: Set the working directory of OpenDALendpoint: Set the network address of redis servercluster_endpoints: Set the network address of redis cluster server. This parameter is mutually exclusive with the endpoint parameter.username: Set the username of Redispassword: Set the password for authenticationdb: Set the DB of redis  You can refer to [RedisBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Redis","url":"/docs/services/redis#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Redis","url":"/docs/services/redis#via-builder","content":" use anyhow::Result; use opendal::services::Redis; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Redis::default(); // this will build a Operator accessing Redis which runs on tcp://localhost:6379 let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Redis","url":"/docs/services/redis#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); map.insert(&quot;endpoint&quot;.to_string(), &quot;tcp://127.0.0.1:6379&quot;.to_string()); map.insert(&quot;username&quot;.to_string(), &quot;your_username&quot;.to_string()); map.insert(&quot;password&quot;.to_string(), &quot;your_password&quot;.to_string()); map.insert(&quot;db&quot;.to_string(), &quot;0&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Redis, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Sqlite","type":0,"sectionRef":"#","url":"/docs/services/sqlite","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Sqlite","url":"/docs/services/sqlite#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Sqlite","url":"/docs/services/sqlite#configuration","content":" root: Set the working directory of OpenDALconnection_string: Set the connection string of sqlite databasetable: Set the table of sqlitekey_field: Set the key field of sqlitevalue_field: Set the value field of sqlite  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Sqlite","url":"/docs/services/sqlite#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Sqlite","url":"/docs/services/sqlite#via-builder","content":" use anyhow::Result; use opendal::services::Sqlite; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Sqlite::default(); builder.root(&quot;/&quot;); builder.connection_string(&quot;file//abc.db&quot;); builder.table(&quot;your_table&quot;); // key field type in the table should be compatible with Rust's &amp;str like text builder.key_field(&quot;key&quot;); // value field type in the table should be compatible with Rust's Vec&lt;u8&gt; like bytea builder.value_field(&quot;value&quot;); let op = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Sqlite","url":"/docs/services/sqlite#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::services::Sqlite; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;connection_string&quot;.to_string(), &quot;file//abc.db&quot;.to_string()); map.insert(&quot;table&quot;.to_string(), &quot;your_table&quot;.to_string()); map.insert(&quot;key_field&quot;.to_string(), &quot;your_key_field&quot;.to_string()); map.insert(&quot;value_field&quot;.to_string(), &quot;your_value_field&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Sqlite, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Sled","type":0,"sectionRef":"#","url":"/docs/services/sled","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Sled","url":"/docs/services/sled#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Sled","url":"/docs/services/sled#configuration","content":" datadir: Set the path to the sled data directory  You can refer to [SledBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Sled","url":"/docs/services/sled#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Sled","url":"/docs/services/sled#via-builder","content":" use anyhow::Result; use opendal::services::Sled; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Sled::default(); builder.datadir(&quot;/tmp/opendal/sled&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Sled","url":"/docs/services/sled#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;datadir&quot;.to_string(), &quot;/tmp/opendal/sled&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Sled, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Supabase","type":0,"sectionRef":"#","url":"/docs/services/supabase","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Supabase","url":"/docs/services/supabase#capabilities","content":"  stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Supabase","url":"/docs/services/supabase#configuration","content":" root: Set the work dir for backend.bucket: Set the container name for backend.endpoint: Set the endpoint for backend.key: Set the authorization key for the backend, do not set if you want to read public bucket  ","version":"Next","tagName":"h2"},{"title":"Authorization keys​","type":1,"pageTitle":"Supabase","url":"/docs/services/supabase#authorization-keys","content":" There are two types of key in the Supabase, one is anon_key(Client key), another one is service_role_key(Secret key). The former one can only write public resources while the latter one can access all resources. Note that if you want to read public resources, do not set the key.  ","version":"Next","tagName":"h3"},{"title":"Example​","type":1,"pageTitle":"Supabase","url":"/docs/services/supabase#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Supabase","url":"/docs/services/supabase#via-builder","content":" use anyhow::Result; use opendal::services::Supabase; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Supabase::default(); builder.root(&quot;/&quot;); builder.bucket(&quot;test_bucket&quot;); builder.endpoint(&quot;http://127.0.0.1:54321&quot;); // this sets up the anon_key, which means this operator can only write public resource builder.key(&quot;some_anon_key&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Supabase","url":"/docs/services/supabase#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/&quot;.to_string()); map.insert(&quot;bucket&quot;.to_string(), &quot;test_bucket&quot;.to_string()); map.insert(&quot;endpoint&quot;.to_string(), &quot;http://127.0.0.1:54321&quot;.to_string()); map.insert(&quot;key&quot;.to_string(), &quot;some_anon_key&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Supabase, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"S3","type":0,"sectionRef":"#","url":"/docs/services/s3","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"S3","url":"/docs/services/s3#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"S3","url":"/docs/services/s3#configuration","content":" root: Set the work dir for backend.bucket: Set the container name for backend.endpoint: Set the endpoint for backend.region: Set the region for backend.access_key_id: Set the access_key_id for backend.secret_access_key: Set the secret_access_key for backend.security_token: Set the security_token for backend.default_storage_class: Set the default storage_class for backend.server_side_encryption: Set the server_side_encryption for backend.server_side_encryption_aws_kms_key_id: Set the server_side_encryption_aws_kms_key_id for backend.server_side_encryption_customer_algorithm: Set the server_side_encryption_customer_algorithm for backend.server_side_encryption_customer_key: Set the server_side_encryption_customer_key for backend.server_side_encryption_customer_key_md5: Set the server_side_encryption_customer_key_md5 for backend.disable_config_load: Disable aws config load from envenable_virtual_host_style: Enable virtual host style.  Refer to [S3Builder]'s public API docs for more information.  ","version":"Next","tagName":"h2"},{"title":"Temporary security credentials​","type":1,"pageTitle":"S3","url":"/docs/services/s3#temporary-security-credentials","content":" OpenDAL now provides support for S3 temporary security credentials in IAM.  The way to take advantage of this feature is to build your S3 backend with Builder::security_token.  But OpenDAL will not refresh the temporary security credentials, please keep in mind to refresh those credentials in time.  ","version":"Next","tagName":"h2"},{"title":"Server Side Encryption​","type":1,"pageTitle":"S3","url":"/docs/services/s3#server-side-encryption","content":" OpenDAL provides full support of S3 Server Side Encryption(SSE) features.  The easiest way to configure them is to use helper functions like  SSE-KMS: server_side_encryption_with_aws_managed_kms_keySSE-KMS: server_side_encryption_with_customer_managed_kms_keySSE-S3: server_side_encryption_with_s3_keySSE-C: server_side_encryption_with_customer_key  If those functions don't fulfill need, low-level options are also provided:  Use service managed kms key server_side_encryption=&quot;aws:kms&quot; Use customer provided kms key server_side_encryption=&quot;aws:kms&quot;server_side_encryption_aws_kms_key_id=&quot;your-kms-key&quot; Use S3 managed key server_side_encryption=&quot;AES256&quot; Use customer key server_side_encryption_customer_algorithm=&quot;AES256&quot;server_side_encryption_customer_key=&quot;base64-of-your-aes256-key&quot;server_side_encryption_customer_key_md5=&quot;base64-of-your-aes256-key-md5&quot;  After SSE have been configured, all requests send by this backed will attach those headers.  Reference: Protecting data using server-side encryption  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"S3","url":"/docs/services/s3#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"S3","url":"/docs/services/s3#via-builder","content":" ","version":"Next","tagName":"h2"},{"title":"Basic Setup​","type":1,"pageTitle":"S3","url":"/docs/services/s3#basic-setup","content":" use std::sync::Arc; use anyhow::Result; use opendal::services::S3; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // Create s3 backend builder. let mut builder = S3::default(); // Set the root for s3, all operations will happen under this root. // // NOTE: the root must be absolute path. builder.root(&quot;/path/to/dir&quot;); // Set the bucket name. This is required. builder.bucket(&quot;test&quot;); // Set the region. This is required for some services, if you don't care about it, for example Minio service, just set it to &quot;auto&quot;, it will be ignored. builder.region(&quot;us-east-1&quot;); // Set the endpoint. // // For examples: // - &quot;https://s3.amazonaws.com&quot; // - &quot;http://127.0.0.1:9000&quot; // - &quot;https://oss-ap-northeast-1.aliyuncs.com&quot; // - &quot;https://cos.ap-seoul.myqcloud.com&quot; // // Default to &quot;https://s3.amazonaws.com&quot; builder.endpoint(&quot;https://s3.amazonaws.com&quot;); // Set the access_key_id and secret_access_key. // // OpenDAL will try load credential from the env. // If credential not set and no valid credential in env, OpenDAL will // send request without signing like anonymous user. builder.access_key_id(&quot;access_key_id&quot;); builder.secret_access_key(&quot;secret_access_key&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"S3 with SSE-C​","type":1,"pageTitle":"S3","url":"/docs/services/s3#s3-with-sse-c","content":" use anyhow::Result; use log::info; use opendal::services::S3; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = S3::default(); // Setup builders builder.root(&quot;/path/to/dir&quot;); builder.bucket(&quot;test&quot;); builder.region(&quot;us-east-1&quot;); builder.endpoint(&quot;https://s3.amazonaws.com&quot;); builder.access_key_id(&quot;access_key_id&quot;); builder.secret_access_key(&quot;secret_access_key&quot;); // Enable SSE-C builder.server_side_encryption_with_customer_key(&quot;AES256&quot;, &quot;customer_key&quot;.as_bytes()); let op = Operator::new(builder)?.finish(); info!(&quot;operator: {:?}&quot;, op); // Writing your testing code here. Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"S3 with SSE-KMS and aws managed kms key​","type":1,"pageTitle":"S3","url":"/docs/services/s3#s3-with-sse-kms-and-aws-managed-kms-key","content":" use anyhow::Result; use log::info; use opendal::services::S3; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = S3::default(); // Setup builders builder.root(&quot;/path/to/dir&quot;); builder.bucket(&quot;test&quot;); builder.region(&quot;us-east-1&quot;); builder.endpoint(&quot;https://s3.amazonaws.com&quot;); builder.access_key_id(&quot;access_key_id&quot;); builder.secret_access_key(&quot;secret_access_key&quot;); // Enable SSE-KMS with aws managed kms key builder.server_side_encryption_with_aws_managed_kms_key(); let op = Operator::new(builder)?.finish(); info!(&quot;operator: {:?}&quot;, op); // Writing your testing code here. Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"S3 with SSE-KMS and customer managed kms key​","type":1,"pageTitle":"S3","url":"/docs/services/s3#s3-with-sse-kms-and-customer-managed-kms-key","content":" use anyhow::Result; use log::info; use opendal::services::S3; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = S3::default(); // Setup builders builder.root(&quot;/path/to/dir&quot;); builder.bucket(&quot;test&quot;); builder.region(&quot;us-east-1&quot;); builder.endpoint(&quot;https://s3.amazonaws.com&quot;); builder.access_key_id(&quot;access_key_id&quot;); builder.secret_access_key(&quot;secret_access_key&quot;); // Enable SSE-KMS with customer managed kms key builder.server_side_encryption_with_customer_managed_kms_key(&quot;aws_kms_key_id&quot;); let op = Operator::new(builder)?.finish(); info!(&quot;operator: {:?}&quot;, op); // Writing your testing code here. Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"S3 with SSE-S3​","type":1,"pageTitle":"S3","url":"/docs/services/s3#s3-with-sse-s3","content":" use anyhow::Result; use log::info; use opendal::services::S3; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = S3::default(); // Setup builders builder.root(&quot;/path/to/dir&quot;); builder.bucket(&quot;test&quot;); builder.region(&quot;us-east-1&quot;); builder.endpoint(&quot;https://s3.amazonaws.com&quot;); builder.access_key_id(&quot;access_key_id&quot;); builder.secret_access_key(&quot;secret_access_key&quot;); // Enable SSE-S3 builder.server_side_encryption_with_s3_key(); let op = Operator::new(builder)?.finish(); info!(&quot;operator: {:?}&quot;, op); // Writing your testing code here. Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"S3","url":"/docs/services/s3#via-config","content":"   RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); map.insert(&quot;bucket&quot;.to_string(), &quot;test&quot;.to_string()); map.insert(&quot;region&quot;.to_string(), &quot;us-east-1&quot;.to_string()); map.insert(&quot;endpoint&quot;.to_string(), &quot;https://s3.amazonaws.com&quot;.to_string()); map.insert(&quot;access_key_id&quot;.to_string(), &quot;access_key_id&quot;.to_string()); map.insert(&quot;secret_access_key&quot;.to_string(), &quot;secret_access_key&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::S3, map)?; Ok(()) }       ","version":"Next","tagName":"h2"},{"title":"Compatible Services​","type":1,"pageTitle":"S3","url":"/docs/services/s3#compatible-services","content":" ","version":"Next","tagName":"h2"},{"title":"AWS S3​","type":1,"pageTitle":"S3","url":"/docs/services/s3#aws-s3","content":" AWS S3 is the default implementations of s3 services. Only bucket is required.  builder.bucket(&quot;&lt;bucket_name&gt;&quot;);   ","version":"Next","tagName":"h3"},{"title":"Alibaba Object Storage Service (OSS)​","type":1,"pageTitle":"S3","url":"/docs/services/s3#alibaba-object-storage-service-oss","content":" OSS is a s3 compatible service provided by Alibaba Cloud.  To connect to OSS, we need to set:  endpoint: The endpoint of oss, for example: https://oss-cn-hangzhou.aliyuncs.combucket: The bucket name of oss.  OSS provide internal endpoint for used at alibabacloud internally, please visit OSS Regions and endpoints for more details.  OSS only supports the virtual host style, users could meet errors like: &lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt; &lt;Error&gt; &lt;Code&gt;SecondLevelDomainForbidden&lt;/Code&gt; &lt;Message&gt;The bucket you are attempting to access must be addressed using OSS third level domain.&lt;/Message&gt; &lt;RequestId&gt;62A1C265292C0632377F021F&lt;/RequestId&gt; &lt;HostId&gt;oss-cn-hangzhou.aliyuncs.com&lt;/HostId&gt; &lt;/Error&gt; In that case, please enable virtual host style for requesting.  builder.endpoint(&quot;https://oss-cn-hangzhou.aliyuncs.com&quot;); builder.region(&quot;&lt;region&gt;&quot;); builder.bucket(&quot;&lt;bucket_name&gt;&quot;); builder.enable_virtual_host_style();   ","version":"Next","tagName":"h3"},{"title":"Minio​","type":1,"pageTitle":"S3","url":"/docs/services/s3#minio","content":" minio is an open-source s3 compatible services.  To connect to minio, we need to set:  endpoint: The endpoint of minio, for example: http://127.0.0.1:9000region: The region of minio. If you don't care about it, just set it to &quot;auto&quot;, it will be ignored.bucket: The bucket name of minio.  builder.endpoint(&quot;http://127.0.0.1:9000&quot;); builder.region(&quot;&lt;region&gt;&quot;); builder.bucket(&quot;&lt;bucket_name&gt;&quot;);   ","version":"Next","tagName":"h3"},{"title":"QingStor Object Storage​","type":1,"pageTitle":"S3","url":"/docs/services/s3#qingstor-object-storage","content":" QingStor Object Storage is a S3-compatible service provided by QingCloud.  To connect to QingStor Object Storage, we need to set:  endpoint: The endpoint of QingStor s3 compatible endpoint, for example: https://s3.pek3b.qingstor.combucket: The bucket name.  ","version":"Next","tagName":"h3"},{"title":"Scaleway Object Storage​","type":1,"pageTitle":"S3","url":"/docs/services/s3#scaleway-object-storage","content":" Scaleway Object Storage is a S3-compatible and multi-AZ redundant object storage service.  To connect to Scaleway Object Storage, we need to set:  endpoint: The endpoint of scaleway, for example: https://s3.nl-ams.scw.cloudregion: The region of scaleway.bucket: The bucket name of scaleway.  ","version":"Next","tagName":"h3"},{"title":"Tencent Cloud Object Storage (COS)​","type":1,"pageTitle":"S3","url":"/docs/services/s3#tencent-cloud-object-storage-cos","content":" COS is a s3 compatible service provided by Tencent Cloud.  To connect to COS, we need to set:  endpoint: The endpoint of cos, for example: https://cos.ap-beijing.myqcloud.combucket: The bucket name of cos.  ","version":"Next","tagName":"h3"},{"title":"Wasabi Object Storage​","type":1,"pageTitle":"S3","url":"/docs/services/s3#wasabi-object-storage","content":" Wasabi is a s3 compatible service.  Cloud storage pricing that is 80% less than Amazon S3.  To connect to wasabi, we need to set:  endpoint: The endpoint of wasabi, for example: https://s3.us-east-2.wasabisys.combucket: The bucket name of wasabi.  Refer to What are the service URLs for Wasabi's different storage regions? for more details.  ","version":"Next","tagName":"h3"},{"title":"Cloudflare R2​","type":1,"pageTitle":"S3","url":"/docs/services/s3#cloudflare-r2","content":" Cloudflare R2 provides s3 compatible API.  Cloudflare R2 Storage allows developers to store large amounts of unstructured data without the costly egress bandwidth fees associated with typical cloud storage services.  To connect to r2, we need to set:  endpoint: The endpoint of r2, for example: https://&lt;account_id&gt;.r2.cloudflarestorage.combucket: The bucket name of r2.region: When you create a new bucket, the data location is set to Automatic by default. So please use auto for region.batch_max_operations: R2's delete objects will return Internal Error if the batch is larger than 700. Please set this value &lt;= 700 to make sure batch delete work as expected.enable_exact_buf_write: R2 requires the non-tailing parts size to be exactly the same. Please enable this option to avoid the error All non-trailing parts must have the same length.  ","version":"Next","tagName":"h3"},{"title":"Google Cloud Storage XML API​","type":1,"pageTitle":"S3","url":"/docs/services/s3#google-cloud-storage-xml-api","content":" Google Cloud Storage XML API provides s3 compatible API.  endpoint: The endpoint of Google Cloud Storage XML API, for example: https://storage.googleapis.combucket: The bucket name.To access GCS via S3 API, please enable features = [&quot;native-tls&quot;] in your Cargo.toml to avoid connection being reset when using rustls. Tracking in https://github.com/seanmonstar/reqwest/issues/1809  ","version":"Next","tagName":"h3"},{"title":"Ceph Rados Gateway​","type":1,"pageTitle":"S3","url":"/docs/services/s3#ceph-rados-gateway","content":" Ceph supports a RESTful API that is compatible with the basic data access model of the Amazon S3 API.  For more information, refer: https://docs.ceph.com/en/latest/radosgw/s3/ ","version":"Next","tagName":"h3"},{"title":"Swift","type":0,"sectionRef":"#","url":"/docs/services/swift","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Swift","url":"/docs/services/swift#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configurations​","type":1,"pageTitle":"Swift","url":"/docs/services/swift#configurations","content":" endpoint: Set the endpoint for backend.container: Swift container.token: Swift personal access token.  Refer to [SwiftBuilder]'s public API docs for more information.  ","version":"Next","tagName":"h2"},{"title":"Examples​","type":1,"pageTitle":"Swift","url":"/docs/services/swift#examples","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Swift","url":"/docs/services/swift#via-builder","content":" use std::sync::Arc; use anyhow::Result; use opendal::services::Swift; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // Create Swift backend builder let mut builder = Swift::default(); // Set the root for swift, all operations will happen under this root builder.root(&quot;/path/to/dir&quot;); // set the endpoint of Swift backend builder.endpoint(&quot;https://openstack-controller.example.com:8080/v1/account&quot;); // set the container name of Swift workspace builder.container(&quot;container&quot;); // set the auth token for builder builder.token(&quot;token&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Swift","url":"/docs/services/swift#via-config","content":"   RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;endpoint&quot;.to_string(), &quot;http://127.0.0.1:8080/v1/AUTH_test&quot;.to_string()); map.insert(&quot;container&quot;.to_string(), &quot;test_container&quot;.to_string()); map.insert(&quot;token&quot;.to_string(), &quot;test_token&quot;.to_string()); map.insert(&quot;root&quot;.to_string(), &quot;/&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Swift, map)?; Ok(()) }       ","version":"Next","tagName":"h3"},{"title":"Compatible Services​","type":1,"pageTitle":"Swift","url":"/docs/services/swift#compatible-services","content":" ","version":"Next","tagName":"h2"},{"title":"OpenStack Swift​","type":1,"pageTitle":"Swift","url":"/docs/services/swift#openstack-swift","content":" OpenStack Swift is the default implementations of swift services.  To connect to OpenStack Swift, we need to set:  endpoint: The endpoint of OpenStack Swift, for example: http://127.0.0.1:8080/v1/AUTH_test.container: The name of OpenStack Swift container.token: OpenStack Swift container personal access token.  builder.endpoint(&quot;http://127.0.0.1:8080/v1/AUTH_test&quot;); builder.container(&quot;container&quot;); builder.token(&quot;token&quot;);   endpoint is the full URL that serves as the access point to all containers under an OpenStack Swift account. It represents the entry point for accessing the resources of the account. Alongside endpoint, token is used as a credential to verify the user's identity and authorize access to the relevant resources. Both endpoint and token can be obtained through OpenStack Swift authentication service.  endpoint consists of server address and port, API version, authenticated account ID. For instance, it might appear as follows:  http://127.0.0.1:8080/v1/AUTH_test.http://192.168.66.88:8080/swift/v1.https://openstack-controller.example.com:8080/v1/account.  Please note that the exact format of endpoint may vary depending on the deployment configuration and version of swift services. Users can refer to the specific services documentation for the correct endpoint format and authentication method.  For more information, refer:  OpenStack Swift API.OpenStack Swift Authentication.  ","version":"Next","tagName":"h3"},{"title":"Ceph Rados Gateway​","type":1,"pageTitle":"Swift","url":"/docs/services/swift#ceph-rados-gateway","content":" Ceph Rados Gateway supports a RESTful API that is compatible with the basic data access model of OpenStack Swift API.  To connect to Ceph Rados Gateway, we need to set:  endpoint: The endpoint of swift services, for example: http://127.0.0.1:8080/swift/v1.container: The name of swift container.token: swift container personal access token.  builder.endpoint(&quot;http://127.0.0.1:8080/swift/v1&quot;); builder.container(&quot;container&quot;); builder.token(&quot;token&quot;);   For more information, refer:  Ceph Rados Gateway Swift API.Ceph Rados Gateway Swift Authentication. ","version":"Next","tagName":"h3"},{"title":"TiKV","type":0,"sectionRef":"#","url":"/docs/services/tikv","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"TiKV","url":"/docs/services/tikv#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"TiKV","url":"/docs/services/tikv#configuration","content":" endpoints: Set the endpoints to the tikv clusterinsecure: Set the insecure flag to the tikv clusterca_path: Set the ca path to the tikv connectioncert_path: Set the cert path to the tikv connectionkey_path: Set the key path to the tikv connection  You can refer to [TiKVBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"TiKV","url":"/docs/services/tikv#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"TiKV","url":"/docs/services/tikv#via-builder","content":" use anyhow::Result; use opendal::services::Tikv; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Tikv::default(); builder.endpoints(vec![&quot;127.0.0.1:2379&quot;.to_string()]); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"TiKV","url":"/docs/services/tikv#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut config = HashMap::new(); config.insert(&quot;endpoints&quot;.to_string(), &quot;127.0.0.1:2379&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::TiKV, config)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"Vercel Artifacts","type":0,"sectionRef":"#","url":"/docs/services/vercel_artifacts","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"Vercel Artifacts","url":"/docs/services/vercel_artifacts#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"Vercel Artifacts","url":"/docs/services/vercel_artifacts#configuration","content":" access_token: set the access_token for Rest API  You can refer to [VercelArtifactsBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"Vercel Artifacts","url":"/docs/services/vercel_artifacts#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"Vercel Artifacts","url":"/docs/services/vercel_artifacts#via-builder","content":" use anyhow::Result; use opendal::services::VercelArtifacts; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // create backend builder let mut builder = VercelArtifacts::default(); builder.access_token(&quot;xxx&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"Vercel Artifacts","url":"/docs/services/vercel_artifacts#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;access_token&quot;.to_string(), &quot;your_access_token&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::VercelArtifacts, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"WebDAV","type":0,"sectionRef":"#","url":"/docs/services/webdav","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"WebDAV","url":"/docs/services/webdav#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Notes​","type":1,"pageTitle":"WebDAV","url":"/docs/services/webdav#notes","content":" Bazel Remote Caching and Ccache HTTP Storage is also part of this service. Users can use webdav to connect those services.  ","version":"Next","tagName":"h2"},{"title":"Configuration​","type":1,"pageTitle":"WebDAV","url":"/docs/services/webdav#configuration","content":" endpoint: set the endpoint for webdavroot: Set the work directory for backend  You can refer to [WebdavBuilder]'s docs for more information  ","version":"Next","tagName":"h2"},{"title":"Example​","type":1,"pageTitle":"WebDAV","url":"/docs/services/webdav#example","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"WebDAV","url":"/docs/services/webdav#via-builder","content":" use anyhow::Result; use opendal::services::Webdav; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { // create backend builder let mut builder = Webdav::default(); builder.endpoint(&quot;127.0.0.1&quot;); builder.username(&quot;xxx&quot;); builder.password(&quot;xxx&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"WebDAV","url":"/docs/services/webdav#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;endpoint&quot;.to_string(), &quot;127.0.0.1&quot;.to_string()); map.insert(&quot;username&quot;.to_string(), &quot;xxx&quot;.to_string()); map.insert(&quot;password&quot;.to_string(), &quot;xxx&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Webdav, map)?; Ok(()) }  ","version":"Next","tagName":"h3"},{"title":"WebHDFS","type":0,"sectionRef":"#","url":"/docs/services/webhdfs","content":"","keywords":"","version":"Next"},{"title":"Capabilities​","type":1,"pageTitle":"WebHDFS","url":"/docs/services/webhdfs#capabilities","content":" This service can be used to:   stat read write create_dir delete copy rename list scan presign blocking  ","version":"Next","tagName":"h2"},{"title":"Differences with HDFS​","type":1,"pageTitle":"WebHDFS","url":"/docs/services/webhdfs#differences-with-hdfs","content":" [Hdfs][crate::services::Hdfs] is powered by HDFS's native java client. Users need to set up the HDFS services correctly. But webhdfs can access from HTTP API and no extra setup needed.  ","version":"Next","tagName":"h2"},{"title":"WebHDFS Compatibility Guidelines​","type":1,"pageTitle":"WebHDFS","url":"/docs/services/webhdfs#webhdfs-compatibility-guidelines","content":" ","version":"Next","tagName":"h2"},{"title":"File Creation and Write​","type":1,"pageTitle":"WebHDFS","url":"/docs/services/webhdfs#file-creation-and-write","content":" For File creation and write operations, OpenDAL WebHDFS is optimized for Hadoop Distributed File System (HDFS) versions 2.9 and later. This involves two API calls in webhdfs, where the initial put call to the namenode is redirected to the datanode handling the file data. The optional noredirect flag can be set to prevent redirection. If used, the API response body contains the datanode URL, which is then utilized for the subsequent put call with the actual file data. OpenDAL automatically sets the noredirect flag with the first put call. This feature is supported starting from HDFS version 2.9.  ","version":"Next","tagName":"h3"},{"title":"Multi-Write Support​","type":1,"pageTitle":"WebHDFS","url":"/docs/services/webhdfs#multi-write-support","content":" OpenDAL WebHDFS supports multi-write operations by creating temporary files in the specified atomic_write_dir. The final concatenation of these temporary files occurs when the writer is closed. However, it's essential to be aware of HDFS concat restrictions for earlier versions, where the target file must not be empty, and its last block must be full. Due to these constraints, the concat operation might fail for HDFS 2.6. This issue, identified as HDFS-6641, has been addressed in later versions of HDFS.  In summary, OpenDAL WebHDFS is designed for optimal compatibility with HDFS, specifically versions 2.9 and later.  ","version":"Next","tagName":"h3"},{"title":"Configurations​","type":1,"pageTitle":"WebHDFS","url":"/docs/services/webhdfs#configurations","content":" root: The root path of the WebHDFS service.endpoint: The endpoint of the WebHDFS service.delegation: The delegation token for WebHDFS.atomic_write_dir: The tmp write dir of multi write for WebHDFS.Needs to be configured for multi write support.  Refer to [Builder]'s public API docs for more information.  ","version":"Next","tagName":"h2"},{"title":"Examples​","type":1,"pageTitle":"WebHDFS","url":"/docs/services/webhdfs#examples","content":" ","version":"Next","tagName":"h2"},{"title":"Via Builder​","type":1,"pageTitle":"WebHDFS","url":"/docs/services/webhdfs#via-builder","content":" use std::sync::Arc; use anyhow::Result; use opendal::services::Webhdfs; use opendal::Operator; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut builder = Webhdfs::default(); // set the root for WebHDFS, all operations will happen under this root // // Note: // if the root is not exists, the builder will automatically create the // root directory for you // if the root exists and is a directory, the builder will continue working // if the root exists and is a folder, the builder will fail on building backend builder.root(&quot;/path/to/dir&quot;); // set the endpoint of webhdfs namenode, controlled by dfs.namenode.http-address // default is http://127.0.0.1:9870 builder.endpoint(&quot;http://127.0.0.1:9870&quot;); // set the delegation_token for builder builder.delegation(&quot;delegation_token&quot;); // set atomic_write_dir for builder builder.atomic_write_dir(&quot;.opendal_tmp/&quot;); let op: Operator = Operator::new(builder)?.finish(); Ok(()) }   ","version":"Next","tagName":"h3"},{"title":"Via Config​","type":1,"pageTitle":"WebHDFS","url":"/docs/services/webhdfs#via-config","content":"     RustNode.jsPython use anyhow::Result; use opendal::Operator; use opendal::Scheme; use std::collections::HashMap; #[tokio::main] async fn main() -&gt; Result&lt;()&gt; { let mut map = HashMap::new(); map.insert(&quot;endpoint&quot;.to_string(), &quot;http://127.0.0.1:9870&quot;.to_string()); map.insert(&quot;root&quot;.to_string(), &quot;/path/to/dir&quot;.to_string()); map.insert(&quot;delegation&quot;.to_string(), &quot;delegation_token&quot;.to_string()); let op: Operator = Operator::via_map(Scheme::Webhdfs, map)?; Ok(()) }  ","version":"Next","tagName":"h3"}],"options":{"id":"default"}}